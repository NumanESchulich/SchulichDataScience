{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data & Package Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Raw File Dataset Path (Full) : https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Full%20Dataset.csv?token=GHSAT0AAAAAACTZRV2CDOCYANJTD5X7E2OQZTSEHXQ\n",
    "# Raw File Dataset Path (50-50): https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/50-50%20Balanced%20Dataset.csv?token=GHSAT0AAAAAACTZRV2DZMBCXNKTGOPFEL7YZTSEGGQ\n",
    "\n",
    "# Read the data file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Full%20Dataset.csv?token=GHSAT0AAAAAACTZRV2CDOCYANJTD5X7E2OQZTSEHXQ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Feature          Chi2        p-value\n",
      "0                GenHlth  22728.069055   0.000000e+00\n",
      "1                 HighBP  17562.446090   0.000000e+00\n",
      "2               DiffWalk  12092.319741   0.000000e+00\n",
      "3               HighChol  10174.074889   0.000000e+00\n",
      "4                    Age   8795.050614   0.000000e+00\n",
      "5               PhysHlth   8078.527635   0.000000e+00\n",
      "6   HeartDiseaseorAttack   7971.155841   0.000000e+00\n",
      "7                 Income   7003.715091   0.000000e+00\n",
      "8              Education   4027.112282   0.000000e+00\n",
      "9           PhysActivity   3539.419370   0.000000e+00\n",
      "10                Stroke   2838.916547   0.000000e+00\n",
      "11              MentHlth   1452.095440  6.353743e-287\n",
      "12             CholCheck   1062.938144  3.751399e-233\n",
      "13                Smoker    937.055759  8.640172e-206\n",
      "14     HvyAlcoholConsump    825.118756  1.865932e-181\n",
      "15               Veggies    811.805975  1.463029e-178\n",
      "16                Fruits    421.611539   1.088121e-93\n",
      "17                   Sex    250.413668   2.109875e-56\n",
      "18           NoDocbcCost    250.313753   2.218395e-56\n",
      "19         AnyHealthcare     66.812372   2.986181e-16\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# List of categorical columns to test\n",
    "categorical_columns = ['HighBP', 'HighChol', 'CholCheck', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
    "                       'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', \n",
    "                       'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', \n",
    "                       'Education', 'Income']\n",
    "\n",
    "# Target variable\n",
    "target = 'Diabetes_binary'\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_results = {}\n",
    "for column in categorical_columns:\n",
    "    contingency_table = pd.crosstab(df[column], df[target])\n",
    "    chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "    chi2_results[column] = {'chi2': chi2, 'p-value': p}\n",
    "\n",
    "# Convert results to DataFrame\n",
    "chi2_results_df = pd.DataFrame.from_dict(chi2_results, orient='index').reset_index()\n",
    "chi2_results_df.columns = ['Feature', 'Chi2', 'p-value']\n",
    "\n",
    "# Sort results by Chi2 score in descending order, then by p-value\n",
    "chi2_results_df.sort_values(by=['Chi2', 'p-value'], ascending=[False, True], inplace=True)\n",
    "chi2_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model I: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8658\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     43739\n",
      "           1       0.54      0.17      0.25      6997\n",
      "\n",
      "    accuracy                           0.87     50736\n",
      "   macro avg       0.71      0.57      0.59     50736\n",
      "weighted avg       0.83      0.87      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Drop ID column as it is not needed for the model\n",
    "data = df.drop(columns=['ID'])\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['Diabetes_binary'])\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model II: K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     43739\n",
      "           1       0.40      0.21      0.27      6997\n",
      "\n",
      "    accuracy                           0.85     50736\n",
      "   macro avg       0.64      0.58      0.59     50736\n",
      "weighted avg       0.82      0.85      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['Diabetes_binary'])\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model III: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Results:\n",
      "Accuracy: 0.7982\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     43739\n",
      "           1       0.30      0.33      0.31      6997\n",
      "\n",
      "    accuracy                           0.80     50736\n",
      "   macro avg       0.59      0.60      0.60     50736\n",
      "weighted avg       0.81      0.80      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['Diabetes_binary'])\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "report_tree = classification_report(y_test, y_pred_tree)\n",
    "\n",
    "# Print results\n",
    "print('Decision Tree Results:')\n",
    "print(f'Accuracy: {accuracy_tree:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model IV: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy: 0.8599\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     43739\n",
      "           1       0.48      0.17      0.25      6997\n",
      "\n",
      "    accuracy                           0.86     50736\n",
      "   macro avg       0.68      0.57      0.59     50736\n",
      "weighted avg       0.82      0.86      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['Diabetes_binary'])\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
    "report_forest = classification_report(y_test, y_pred_forest)\n",
    "\n",
    "# Print results\n",
    "print('Random Forest Results:')\n",
    "print(f'Accuracy: {accuracy_forest:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model V: Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classification Results:\n",
      "Accuracy: 0.7720\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86     43739\n",
      "           1       0.32      0.57      0.41      6997\n",
      "\n",
      "    accuracy                           0.77     50736\n",
      "   macro avg       0.62      0.69      0.63     50736\n",
      "weighted avg       0.84      0.77      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['Diabetes_binary'])\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (Naive Bayes doesn't require standardization, but we'll include it for consistency)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "# Print results\n",
    "print('Naive Bayes Classification Results:')\n",
    "print(f'Accuracy: {accuracy_nb:.4f}')\n",
    "print('Classification Report:')\n",
    "print(report_nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
