{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data & Package Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "Training_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Train%20Dataset%20(Clustered%20%2B%20Feature%20Engineering%20%2B%20SMOTEENN).csv\"\n",
    "Testing_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Untouched%20Test%20Data.csv\"\n",
    "\n",
    "# Read the train data file\n",
    "df = pd.read_csv(Training_Data_Path)\n",
    "test_df = pd.read_csv(Testing_Data_Path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi2</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PhysicalCondition</th>\n",
       "      <td>92089.220561</td>\n",
       "      <td>1.062163e-122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LackOfDisease</th>\n",
       "      <td>80808.650041</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GenHlth</th>\n",
       "      <td>77403.395543</td>\n",
       "      <td>8.301916e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Income</th>\n",
       "      <td>63666.865784</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>62450.613724</td>\n",
       "      <td>1.256976e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>60481.270467</td>\n",
       "      <td>2.672064e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoHighBP</th>\n",
       "      <td>59367.616335</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lifestyle</th>\n",
       "      <td>50214.844518</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoHighChol</th>\n",
       "      <td>42311.306944</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysHlth</th>\n",
       "      <td>32988.537211</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>32827.327392</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDiffWalk</th>\n",
       "      <td>31061.308351</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MentHlth</th>\n",
       "      <td>28341.651852</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhysActivity</th>\n",
       "      <td>19799.832552</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoHeartDiseaseorAttack</th>\n",
       "      <td>17489.033312</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoSmoker</th>\n",
       "      <td>14884.037749</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fruits</th>\n",
       "      <td>10596.888980</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veggies</th>\n",
       "      <td>8293.191487</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoStroke</th>\n",
       "      <td>6502.563815</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>4641.887803</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CholCheck</th>\n",
       "      <td>1841.922304</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <td>1741.284821</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoHvyAlcoholConsump</th>\n",
       "      <td>450.525076</td>\n",
       "      <td>5.544275e-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <td>270.219914</td>\n",
       "      <td>1.016202e-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                chi2        p-value\n",
       "PhysicalCondition       92089.220561  1.062163e-122\n",
       "LackOfDisease           80808.650041   0.000000e+00\n",
       "GenHlth                 77403.395543  8.301916e-232\n",
       "Income                  63666.865784   1.000000e+00\n",
       "BMI                     62450.613724   1.256976e-11\n",
       "Age                     60481.270467   2.672064e-08\n",
       "NoHighBP                59367.616335   0.000000e+00\n",
       "Lifestyle               50214.844518   1.000000e+00\n",
       "NoHighChol              42311.306944   0.000000e+00\n",
       "PhysHlth                32988.537211   1.000000e+00\n",
       "Education               32827.327392   1.000000e+00\n",
       "NoDiffWalk              31061.308351   0.000000e+00\n",
       "MentHlth                28341.651852   1.000000e+00\n",
       "PhysActivity            19799.832552   0.000000e+00\n",
       "NoHeartDiseaseorAttack  17489.033312   0.000000e+00\n",
       "NoSmoker                14884.037749   0.000000e+00\n",
       "Fruits                  10596.888980   0.000000e+00\n",
       "Veggies                  8293.191487   0.000000e+00\n",
       "NoStroke                 6502.563815   0.000000e+00\n",
       "Sex                      4641.887803   0.000000e+00\n",
       "CholCheck                1841.922304   0.000000e+00\n",
       "NoDocbcCost              1741.284821   0.000000e+00\n",
       "NoHvyAlcoholConsump       450.525076  5.544275e-100\n",
       "AnyHealthcare             270.219914   1.016202e-60"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting relevant columns for the ChiSquare test\n",
    "relevant_columns = df.columns.drop(['ID', 'Diabetes_binary'])\n",
    "\n",
    "# Performing ChiSquare test for each column\n",
    "chi2_results = {}\n",
    "for column in relevant_columns:\n",
    "    contingency_table = pd.crosstab(df[column], df['Diabetes_binary'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    chi2_results[column] = {'chi2': chi2, 'p-value': p}\n",
    "\n",
    "# Sorting the results by chi2 value\n",
    "chi2_results_sorted = pd.DataFrame(chi2_results).T.sort_values(by='chi2', ascending=False)\n",
    "\n",
    "# Displaying the sorted results\n",
    "chi2_results_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.5853831598864712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.54      0.69     43667\n",
      "           1       0.23      0.87      0.37      7069\n",
      "\n",
      "    accuracy                           0.59     50736\n",
      "   macro avg       0.60      0.71      0.53     50736\n",
      "weighted avg       0.86      0.59      0.65     50736\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8086959949542731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88     43667\n",
      "           1       0.37      0.53      0.44      7069\n",
      "\n",
      "    accuracy                           0.81     50736\n",
      "   macro avg       0.64      0.69      0.66     50736\n",
      "weighted avg       0.84      0.81      0.82     50736\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.7790523494165879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86     43667\n",
      "           1       0.34      0.63      0.44      7069\n",
      "\n",
      "    accuracy                           0.78     50736\n",
      "   macro avg       0.64      0.72      0.65     50736\n",
      "weighted avg       0.85      0.78      0.80     50736\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.8562164932198045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92     43667\n",
      "           1       0.40      0.06      0.10      7069\n",
      "\n",
      "    accuracy                           0.86     50736\n",
      "   macro avg       0.63      0.52      0.51     50736\n",
      "weighted avg       0.80      0.86      0.81     50736\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define features and target for training data\n",
    "X_train = df[['PhysicalCondition', 'LackOfDisease', 'Age', 'BMI']]\n",
    "y_train = df['Diabetes_binary']\n",
    "\n",
    "# Define features and target for testing data\n",
    "X_test = test_df[['PhysicalCondition', 'LackOfDisease', 'Age', 'BMI']]\n",
    "y_test = test_df['Diabetes_binary']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    # Evaluate the model\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Selected Model: Random Forest Classifier\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.8420648060548723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     43667\n",
      "           1       0.42      0.36      0.39      7069\n",
      "\n",
      "    accuracy                           0.84     50736\n",
      "   macro avg       0.66      0.64      0.65     50736\n",
      "weighted avg       0.83      0.84      0.84     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Selected Model: Random Forest Classifier\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier - with SMOTE & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Selected Model: Random Forest Classifier\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.8342399873856827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90     43667\n",
      "           1       0.41      0.41      0.41      7069\n",
      "\n",
      "    accuracy                           0.83     50736\n",
      "   macro avg       0.65      0.65      0.65     50736\n",
      "weighted avg       0.83      0.83      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the specific columns for training\n",
    "X_train = df[['PhysicalCondition', 'LackOfDisease', 'Age', 'BMI', 'Income']]\n",
    "y_train = df['Diabetes_binary']  \n",
    "\n",
    "# Select the specific columns for testing\n",
    "X_test = test_df[['PhysicalCondition', 'LackOfDisease', 'Age', 'BMI', 'Income']]\n",
    "y_test = test_df['Diabetes_binary']  \n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Selected Model: Random Forest Classifier\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier - with SMOTE & ALL RAW COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Selected Model: Random Forest Classifier\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.8172500788394829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89     43667\n",
      "           1       0.38      0.52      0.44      7069\n",
      "\n",
      "    accuracy                           0.82     50736\n",
      "   macro avg       0.65      0.69      0.67     50736\n",
      "weighted avg       0.84      0.82      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select the specific columns for training\n",
    "X_train = df[['CholCheck', 'BMI', 'PhysActivity', 'Fruits', 'Veggies', 'AnyHealthcare', 'NoDocbcCost', \n",
    "    'GenHlth', 'MentHlth', 'PhysHlth', 'Sex', 'Age', 'Education', 'Income', \n",
    "    'NoDiffWalk', 'NoHighBP', 'NoHighChol', 'NoHeartDiseaseorAttack', 'NoStroke', \n",
    "    'NoSmoker', 'NoHvyAlcoholConsump']]\n",
    "y_train = df['Diabetes_binary']  \n",
    "\n",
    "# Select the specific columns for testing\n",
    "X_test = test_df[['CholCheck', 'BMI', 'PhysActivity', 'Fruits', 'Veggies', 'AnyHealthcare', 'NoDocbcCost', \n",
    "    'GenHlth', 'MentHlth', 'PhysHlth', 'Sex', 'Age', 'Education', 'Income', \n",
    "    'NoDiffWalk', 'NoHighBP', 'NoHighChol', 'NoHeartDiseaseorAttack', 'NoStroke', \n",
    "    'NoSmoker', 'NoHvyAlcoholConsump']]\n",
    "y_test = test_df['Diabetes_binary']  \n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Selected Model: Random Forest Classifier\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier - with RAW DATA & ALL RAW COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Selected Model: Random Forest Classifier\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Accuracy: 0.8572414064963734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     43739\n",
      "           1       0.45      0.15      0.23      6997\n",
      "\n",
      "    accuracy                           0.86     50736\n",
      "   macro avg       0.66      0.56      0.58     50736\n",
      "weighted avg       0.82      0.86      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Full%20Dataset%20(RAW).csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Define the target variable and features based on the actual column names\n",
    "features = ['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', \n",
    "            'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', \n",
    "            'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
    "target = 'Diabetes_binary'\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Selected Model: Random Forest Classifier\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Models Run on SMOTE Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Selected Model: Logistic Regression\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.7010209713024282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80     43667\n",
      "           1       0.28      0.72      0.40      7069\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.61      0.71      0.60     50736\n",
      "weighted avg       0.85      0.70      0.75     50736\n",
      "\n",
      "Training Naive Bayes...\n",
      "Selected Model: Naive Bayes\n",
      "Best Parameters: Default parameters\n",
      "Accuracy: 0.6264585304320404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.60      0.73     43667\n",
      "           1       0.25      0.82      0.38      7069\n",
      "\n",
      "    accuracy                           0.63     50736\n",
      "   macro avg       0.60      0.71      0.56     50736\n",
      "weighted avg       0.85      0.63      0.68     50736\n",
      "\n",
      "Training Linear Discriminant Analysis...\n",
      "Selected Model: Linear Discriminant Analysis\n",
      "Best Parameters: Default parameters\n",
      "Accuracy: 0.5930305897193314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.55      0.70     43667\n",
      "           1       0.24      0.85      0.37      7069\n",
      "\n",
      "    accuracy                           0.59     50736\n",
      "   macro avg       0.60      0.70      0.53     50736\n",
      "weighted avg       0.86      0.59      0.65     50736\n",
      "\n",
      "Training K-nearest Neighbors...\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Selected Model: K-nearest Neighbors\n",
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
      "Accuracy: 0.8552507095553453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92     43667\n",
      "           1       0.38      0.06      0.10      7069\n",
      "\n",
      "    accuracy                           0.86     50736\n",
      "   macro avg       0.62      0.52      0.51     50736\n",
      "weighted avg       0.80      0.86      0.81     50736\n",
      "\n",
      "Training Random Forest...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Selected Model: Random Forest\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.7444615263323873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84     43667\n",
      "           1       0.31      0.66      0.42      7069\n",
      "\n",
      "    accuracy                           0.74     50736\n",
      "   macro avg       0.62      0.71      0.63     50736\n",
      "weighted avg       0.84      0.74      0.78     50736\n",
      "\n",
      "Training Gradient Boosted Trees...\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Selected Model: Gradient Boosted Trees\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200}\n",
      "Accuracy: 0.7004296751813308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.69      0.80     43667\n",
      "           1       0.28      0.74      0.41      7069\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.61      0.72      0.60     50736\n",
      "weighted avg       0.85      0.70      0.74     50736\n",
      "\n",
      "\n",
      "Summary Table:\n",
      "                          Model  \\\n",
      "0           Logistic Regression   \n",
      "1                   Naive Bayes   \n",
      "2  Linear Discriminant Analysis   \n",
      "3           K-nearest Neighbors   \n",
      "4                 Random Forest   \n",
      "5        Gradient Boosted Trees   \n",
      "\n",
      "                                     Best Parameters  Accuracy  \n",
      "0   {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}  0.701021  \n",
      "1                                 Default parameters  0.626459  \n",
      "2                                 Default parameters  0.593031  \n",
      "3  {'metric': 'euclidean', 'n_neighbors': 3, 'wei...  0.855251  \n",
      "4  {'max_depth': 10, 'min_samples_leaf': 4, 'min_...  0.744462  \n",
      "5  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...  0.700430  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Paths to the training and testing data\n",
    "Training_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Train%20Dataset%20(Clustered%20%2B%20Feature%20Engineering%20%2B%20SMOTEENN).csv\"\n",
    "Testing_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Untouched%20Test%20Data.csv\"\n",
    "\n",
    "# Read the train and test data files\n",
    "df = pd.read_csv(Training_Data_Path)\n",
    "test_df = pd.read_csv(Testing_Data_Path)\n",
    "\n",
    "# Assuming df and test_df are your dataframes\n",
    "df['NotOverweight'] = df['BMI'].apply(lambda x: 0 if x >= 25 else 1)\n",
    "test_df['NotOverweight'] = test_df['BMI'].apply(lambda x: 0 if x >= 25 else 1)\n",
    "\n",
    "# Select the specific columns for training\n",
    "X_train = df[['PhysicalCondition', 'LackOfDisease', 'Age', 'Income', 'NotOverweight']]\n",
    "y_train = df['Diabetes_binary']\n",
    "\n",
    "# Select the specific columns for testing\n",
    "X_test = test_df[['PhysicalCondition', 'LackOfDisease', 'Age', 'Income', 'NotOverweight']]\n",
    "y_test = test_df['Diabetes_binary']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grids for Grid Search\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(class_weight='balanced', max_iter=10000), param_grid_lr),\n",
    "    'Naive Bayes': (GaussianNB(), {}),\n",
    "    'Linear Discriminant Analysis': (LinearDiscriminantAnalysis(), {}),\n",
    "    'K-nearest Neighbors': (KNeighborsClassifier(), param_grid_knn),\n",
    "    'Random Forest': (RandomForestClassifier(), param_grid_rf),\n",
    "    'Gradient Boosted Trees': (GradientBoostingClassifier(), param_grid_gb)\n",
    "}\n",
    "\n",
    "# Initialize lists to store results\n",
    "model_names = []\n",
    "best_params_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        best_params = \"Default parameters\"\n",
    "        best_model = model\n",
    "    \n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    model_names.append(model_name)\n",
    "    best_params_list.append(best_params)\n",
    "    accuracy_list.append(accuracy)\n",
    "    \n",
    "    print(f\"Selected Model: {model_name}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(report)\n",
    "    \n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Best Parameters': best_params_list,\n",
    "    'Accuracy': accuracy_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost (Run on GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 200}\n",
      "Accuracy: 0.7041942604856513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80     43667\n",
      "           1       0.28      0.73      0.41      7069\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.61      0.71      0.60     50736\n",
      "weighted avg       0.85      0.70      0.75     50736\n",
      "\n",
      "   Accuracy                                    Best Parameters\n",
      "0  0.704194  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Numan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:23:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGwCAYAAADFZj2cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABHQ0lEQVR4nO3de1wU9f4/8NcusNx3ERUQQUVJhURJTKTSNEksK007qVnhtaOBJeStMkSt6KenvKRp51hi5ysn7aIlGkaYmomZGHlJMAxDhUVMYQVlF3bn9wcxumEuyyxymdfz8ZjHo535zMx7PBz2zef9+XxGIQiCACIiIqJbUDZ1AERERNT8MWEgIiIii5gwEBERkUVMGIiIiMgiJgxERERkERMGIiIisogJAxEREVlk39QBSGEymVBYWAh3d3coFIqmDoeIiKwkCAKuXLkCX19fKJWN9zdsZWUlDAaD5OuoVCo4OTnZIKKWp0UnDIWFhfD392/qMIiISKKzZ8/Cz8+vUa5dWVmJgM5u0F4wSr6Wj48P8vPzZZk0tOiEwd3dHQDw+5EuULuxukKt04DVU5s6BKJGY9RXIu/9xeLv88ZgMBigvWDE71ldoHZv+HeF7ooJncPOwGAwMGFoaWrLEGo3paQfAqLmzM5Rfr+YSH5uR1nZzV0BN/eG38cEeZe+W3TCQEREVF9GwQSjhLcnGQWT7YJpgfhnORERyYIJguTNGmvXrkXv3r2hVquhVqsRERGBr776SjxeWVmJmJgYtG3bFm5ubhgzZgyKi4vNrlFQUIARI0bAxcUFXl5emDNnDqqrq83a7NmzB3379oWjoyMCAwORnJxcJ5Y1a9agS5cucHJyQnh4OA4dOmTVswBMGIiIiBqFn58f3nrrLWRlZeHw4cN44IEHMHLkSJw4cQIAEBcXh+3bt+OTTz7B3r17UVhYiNGjR4vnG41GjBgxAgaDAQcOHMDGjRuRnJyMhIQEsU1+fj5GjBiBIUOGIDs7G7NmzcLUqVOxa9cusc3mzZsRHx+PhQsX4siRI+jTpw+ioqJw4cIFq55H0ZJfb63T6aDRaHD5VFeOYaBWK+Sd55s6BKJGY9RXInfVKygrK4NarW6Ue9R+VxTm+kke9Ojb45ykWD09PbFs2TI88cQTaN++PVJSUvDEE08AAHJychAUFITMzEwMGDAAX331FR555BEUFhbC29sbALBu3TrMmzcPJSUlUKlUmDdvHnbs2IHjx4+L9xg3bhxKS0uRlpYGAAgPD8fdd9+N1atXA6hZksDf3x8zZ87E/Pnz6x07v2WJiEgWjIIgeQNqEpAbN71eb/neRiM+/vhjVFRUICIiAllZWaiqqkJkZKTYpmfPnujUqRMyMzMBAJmZmQgJCRGTBQCIioqCTqcTeykyMzPNrlHbpvYaBoMBWVlZZm2USiUiIyPFNvXFhIGIiMgK/v7+0Gg04paUlPS3bY8dOwY3Nzc4Ojpi+vTp2Lp1K4KDg6HVaqFSqeDh4WHW3tvbG1qtFgCg1WrNkoXa47XHbtVGp9Ph2rVruHjxIoxG403b1F6jvjhLgoiIZKEhAxf/ej5Qs8jUjSUJR0fHvz2nR48eyM7ORllZGT799FNER0dj7969DY6hKTFhICIiWTBBgNEGCUPtrIf6UKlUCAwMBACEhYXhxx9/xMqVKzF27FgYDAaUlpaa9TIUFxfDx8cHQM2qkn+dzVA7i+LGNn+dWVFcXAy1Wg1nZ2fY2dnBzs7upm1qr1FfLEkQERHdJiaTCXq9HmFhYXBwcEBGRoZ4LDc3FwUFBYiIiAAARERE4NixY2azGdLT06FWqxEcHCy2ufEatW1qr6FSqRAWFmbWxmQyISMjQ2xTX+xhICIiWbBVSaK+Xn75ZTz00EPo1KkTrly5gpSUFOzZswe7du2CRqPBlClTEB8fD09PT6jVasycORMREREYMGAAAGDYsGEIDg7GM888g6VLl0Kr1WLBggWIiYkRyyDTp0/H6tWrMXfuXEyePBm7d+/Gli1bsGPHDjGO+Ph4REdHo1+/fujfvz9WrFiBiooKTJo0yarnYcJARESycONMh4aeb40LFy7g2WefRVFRETQaDXr37o1du3bhwQcfBAAsX74cSqUSY8aMgV6vR1RUFN577z3xfDs7O6SmpmLGjBmIiIiAq6sroqOjsXjxYrFNQEAAduzYgbi4OKxcuRJ+fn5Yv349oqKixDZjx45FSUkJEhISoNVqERoairS0tDoDIS3hOgxEzRzXYaDW7Hauw3DqpDfcJXxXXLliQveg4kaNtTljDwMREcmC6c9NyvlyxoSBiIhkwShxloSUc1sDJgxERCQLRgES31Zpu1haIhb+iYiIyCL2MBARkSxwDIM0TBiIiEgWTFDACIWk8+WMJQkiIiKyiD0MREQkCyahZpNyvpwxYSAiIlkwSixJSDm3NWBJgoiIiCxiDwMREckCexikYcJARESyYBIUMAkSZklIOLc1YEmCiIiILGIPAxERyQJLEtIwYSAiIlkwQgmjhI51ow1jaYmYMBARkSwIEscwCBzDQERERHRr7GEgIiJZ4BgGaZgwEBGRLBgFJYyChDEMMl8amiUJIiIisog9DEREJAsmKGCS8HeyCfLuYmDCQEREssAxDNKwJEFEREQWsYeBiIhkQfqgR5YkiIiIWr2aMQwSXj7FkgQRERHRrbGHgYiIZMEk8V0SnCVBREQkAxzDIA0TBiIikgUTlFyHQQKOYSAiIiKL2MNARESyYBQUMEp4RbWUc1sDJgxERCQLRomDHo0sSRARERHdGnsYiIhIFkyCEiYJsyRMnCVBRETU+rEkIQ1LEkRERGQRexiIiEgWTJA208Fku1BaJCYMREQkC9IXbpJ3p7y8n56IiIjqhT0MREQkC9LfJSHvv7GZMBARkSyYoIAJUsYwcKVHIiKiVo89DNLI++mJiIioXtjDQEREsiB94SZ5/43NhIGIiGTBJChgkrIOg8zfVinvdImIiIjqhT0MREQkCyaJJQm5L9zEhIGIiGRB+tsq5Z0wyPvpiYiIqF7Yw0BERLJghAJGCYsvSTm3NWDCQEREssCShDTyfnoiIiKqF/YwEBGRLBghraxgtF0oLRJ7GIiISBZqSxJSNmskJSXh7rvvhru7O7y8vDBq1Cjk5uaatRk8eDAUCoXZNn36dLM2BQUFGDFiBFxcXODl5YU5c+agurrarM2ePXvQt29fODo6IjAwEMnJyXXiWbNmDbp06QInJyeEh4fj0KFDVj0PEwYiIpKF2pdPSdmssXfvXsTExODgwYNIT09HVVUVhg0bhoqKCrN206ZNQ1FRkbgtXbr0esxGI0aMGAGDwYADBw5g48aNSE5ORkJCgtgmPz8fI0aMwJAhQ5CdnY1Zs2Zh6tSp2LVrl9hm8+bNiI+Px8KFC3HkyBH06dMHUVFRuHDhQr2fhyUJIiKiRpCWlmb2OTk5GV5eXsjKysKgQYPE/S4uLvDx8bnpNb7++mv88ssv+Oabb+Dt7Y3Q0FAsWbIE8+bNQ2JiIlQqFdatW4eAgAC8/fbbAICgoCDs378fy5cvR1RUFADgnXfewbRp0zBp0iQAwLp167Bjxw58+OGHmD9/fr2ehz0MREQkCwIUMEnYhD/HP+h0OrNNr9fX6/5lZWUAAE9PT7P9mzZtQrt27dCrVy+8/PLLuHr1qngsMzMTISEh8Pb2FvdFRUVBp9PhxIkTYpvIyEiza0ZFRSEzMxMAYDAYkJWVZdZGqVQiMjJSbFMf7GEgIiJZaEhZ4a/nA4C/v7/Z/oULFyIxMfGW55pMJsyaNQv33nsvevXqJe5/6qmn0LlzZ/j6+uLo0aOYN28ecnNz8fnnnwMAtFqtWbIAQPys1Wpv2Uan0+HatWu4fPkyjEbjTdvk5OTU8+mZMBAREVnl7NmzUKvV4mdHR0eL58TExOD48ePYv3+/2f7nnntO/O+QkBB06NABQ4cOxenTp9GtWzfbBW0DTBiIiEgWbPV6a7VabZYwWBIbG4vU1FTs27cPfn5+t2wbHh4OAMjLy0O3bt3g4+NTZzZDcXExAIjjHnx8fMR9N7ZRq9VwdnaGnZ0d7Ozsbtrm78ZO3AzHMBARkSwY/3xbpZTNGoIgIDY2Flu3bsXu3bsREBBg8Zzs7GwAQIcOHQAAEREROHbsmNlshvT0dKjVagQHB4ttMjIyzK6Tnp6OiIgIAIBKpUJYWJhZG5PJhIyMDLFNfbCHgYiIqBHExMQgJSUFX3zxBdzd3cUxBxqNBs7Ozjh9+jRSUlLw8MMPo23btjh69Cji4uIwaNAg9O7dGwAwbNgwBAcH45lnnsHSpUuh1WqxYMECxMTEiKWQ6dOnY/Xq1Zg7dy4mT56M3bt3Y8uWLdixY4cYS3x8PKKjo9GvXz/0798fK1asQEVFhThroj6YMBARkSzYqiRRX2vXrgVQszjTjTZs2ICJEydCpVLhm2++Eb+8/f39MWbMGCxYsEBsa2dnh9TUVMyYMQMRERFwdXVFdHQ0Fi9eLLYJCAjAjh07EBcXh5UrV8LPzw/r168Xp1QCwNixY1FSUoKEhARotVqEhoYiLS2tzkDIW1EIgiBY9S/QjOh0Omg0Glw+1RVqd1ZXqHUKeef5pg6BqNEY9ZXIXfUKysrKrBoXYI3a74rY/Y/D0c2hwdfRl1dh9X1bGzXW5ozfskRERGQRSxJERCQLRkEBo4SShJRzWwMmDEREJAu3ewxDa8OEgYiIZEFowBsn/3q+nMn76YmIiKhe2MNARESyYIQCRkgYwyDh3NaACQMREcmCSZA2DsHUYhchsA2WJIiIiMgi9jC0cts3tsWOj9qh+KwKANC5RyUmxGlx9wNXAACGSgX+vcgXe75sgyq9AmGDr2Bm0jm0aV8tXiPKN7TOdV9+7wwGjyoFAPxrViekb/Gs06ZT92v4z55cAMDVciU2Lu2AA19pUPqHPbrdeQ0zlpxDj9BrNn5ikpuwjoWY2C8bwd4l8HK7ihe/GI7dp6+v2T8j4kc81CMP3u7lqDYq8Utxe6z6PhzHtNdXuFM7VeKVIftxf9czMAkKfJPXFW99ex+uVV1f5OeezgV4/p4fEdj2MvTVdsg63wH/2nsPCnXXF/AZ0fMUJt2djU4eZSjXq7D/TCe8vS8CZZVOt+cfg27JJHHQo5RzWwN5P70MtO9QhcmvFGJ1Wi7e/eoU+tx7BYmTAnAmt+YX2LrEjjiYrsGC98/gX5/n4VKxAxZP6VLnOi8tL8D/so+L2z3Dy8RjMxafMzv2f4dPwL1NNQY9cr3N8pf8cWSfG+a++zvWZeQg7P4rmD82EBeLGr7qGhEAODtU4VRJW7yxe+BNj/9+WYM3dw/EmI/G4tnNj+O8zh3vj0lFG+fryer/e+gbdGt7Cc999ihitz2MsI5FSHxwj3i8o1qHVSPTcKigI5747z8w/fNH0Ma5Essf3SW2CfUtwhvDd+Pz4z3x+MaxeCl1GHr5FJtdh5qWCQrJm5w1i4RhzZo16NKlC5ycnBAeHl7nVZ7UcAOG6dB/6BV07GqAXzc9Js3XwsnVhJwsF1TolNj1P0/8M/E8Qu8rxx29ryH+nQL8ctgNJ7NczK7jpjbC06ta3FRO14t5rmqT2bFff3ZBeakdho37AwCgv6bA/p0emLqgCCEDKtAxwIBnZmvh20WP1I/a3tZ/D2p99p/pjHcPhGN3XtebHt+Z0x0HC/xwrkyN0394Ytnee+HuaED3djU/nwGel3FfwFksTB+MY1pv/FTYAUnf3ofhPfLQ3rUCABDsXQKlQsC734fjXJkGJy+0R/LhUPT0ugh7pREA0KdDMQp17kj5qTfO69T4qbADPj16J0J8Ltw0LqKWpskThs2bNyM+Ph4LFy7EkSNH0KdPH0RFRZm9ypNsw2gE9mzzgP6qEkH9KvDrURdUVylx18BysU2nO/Tw6mjAySxXs3NXv9oR/7izF2Y+fAd2/c8Tt3oDSdr/PHHXwCvw9qv6874KmIwKqBxNZu0cnUw4ccjNdg9IZIG90ognQn6BrlKF3JKaZLVPBy10lSr8Uuwltjv4ux9MggIhHYoBAL8Ut4cgAKN65UCpMMFNpcejQadw8Hc/VJvsAAA/F3nDx70cAwN+ByCgrctVPNj9NL7L73Tbn5NurnalRymbnDX5GIZ33nkH06ZNE1+xuW7dOuzYsQMffvgh5s+f38TRtQ75J50w69E7YNAr4exqQsIH+ejcXY/Tx53hoDLBTWM0a+/RvgqXLlz/0Xh2ThFC7y2Ho7MJWXvd8e4rfrhWocSoqRfr3OsPrT1+/FaN+Wt+F/e5uJkQFFaBlBU+6HTHGXi0r8aebW1wMssVvl30jffgRH8aFHAGy0akw8mhGiUVrnjus0dRWukMAGjnehV/XHU2a28UlCirdEQ7l6sAgPM6Nf75+aP414ivkRC5F/ZKAdmF3nh+6wjxnOzCDpi/MxLLRqRDZWeEg50J357u/LelErr9OIZBmiZ9eoPBgKysLERGRor7lEolIiMjkZmZWae9Xq+HTqcz28gyv256vJeei1U7TuGRZy/iXy92xu+nHOt9/oS4YtzZvwKBIdcwNvYC/jHjAj5Z63XTtumfeMJNbTQb4wAAc9/9HYIAPNW3Fx7p0gfbPmiHwaMuQyHv///RbfLj2Y544v+exDMfP47vz/jjX498DU/nq/U+v63LVSx8cA+++KUHxm8ag4mbR6LKaId3HtkFoKa7ravnJcwbsh/rDoZh3KYn8M/PRqCj+gpei9zXSE9FdHs16a/rixcvwmg01nkft7e3N7RabZ32SUlJ0Gg04ubv73+7Qm3RHFQCOgYYcEfva5j8ShECgq9h2/r28PSqRpVBifIyO7P2pSUO8PSq/purAT37XsXFIhUMevPuOUEAdn3cFkOfuAQHlXnNwreLAf/6PA9f5B3F/x0+gXd3/orqKgU6dGYPAzW+a9UOOFuqwdEiHyz8egiMJiUe75UDALhY4YK2LuazdewUJmic9Lh4tWYsz/jQ4yjXq7D8uwjklLRH1nlfvPzVUAzofB69/yxbTO3/E7ILfZB8+C6cutgWB37vhNczBmF0rxy0+3MsBDUtExTi+yQatHHQY8vx8ssvo6ysTNzOnj3b1CG1SIIAVBmUuKP3Vdg7mPDT/uvjCM7mOeLCeRWCwv7+F9zpE85w86iGytE8KTia6YbCfEcMH3/pb891cjGhrXc1rpTaIWuvGhFR7CWi20+pEKCyrynF/VzkA7WTAcFeJeLx/p3OQ6kQcKyo5o8ZJ/vqOgv+1Naza/c6OVTVaWP6SxtqWoLEGRKCzP+XbNIxDO3atYOdnR2Ki4vN9hcXF8PHx6dOe0dHRzg61r8rnYAP3+yAux/QoX3HKlwrV+LbrW1w9IAb3kg5DVe1CVHjL+HfiR3h7mGEq7sRa171Q1BYBYLCarprD36txuUSewSFXYWDowlH9rnj41VeeGJ6SZ177fqfJ3r2rUCXnpV1jh3e4w5BAPy76XE+X4X1SzrCP7ASw8b+0ej/BtS6OTtUoZPH9RJYR40OPdpfRFmlI8quOWFaeBb2/NYFJeWuaONciXGhx+HlVoGvT3UDAORfaoP9+f5Y+OAeLMkYBHulCa888B3ScgNRUlEz+Hdffic8E/Yzpg84jJ05gXBVVeGF+37A+TJ35JS0AwDsPd0FCx/ciyd7H8eB3zuhnWsF5g3+HkeLvMTrUNPi2yqladKEQaVSISwsDBkZGRg1ahQAwGQyISMjA7GxsU0ZWqtRetEey17ojEsX7OHibkRAUCXeSDmNsPtrZkZMT6z5S2rJtC6o0ivQb/AVxCadE8+3cxCwPbkd3k90hCDUlBb+mViIhyaYf9FX6JTYv8MD05ecw81U6OywIakDLhY5wN3DiHsfLsWk+UWw5zIMJNGd3hew4ckvxc9zBx8AAHxxogcWfzMIAZ6leOzOr9HG6RpKK51wQuuF6M2jcPqP64uNzfsqEq8+8B3WP7G9ZuGmX7si6dv7xOOHzvph3s5ITOqXjUn9fsK1anscLfTBjM9HQF9d82v0i196wlVVhfGhxzH7/kxc0atw6GxHLP9uwG36lyBqXApBuNUEuca3efNmREdH4/3330f//v2xYsUKbNmyBTk5OXXGNvyVTqeDRqPB5VNdoXZvUdUVonoLeef5pg6BqNEY9ZXIXfUKysrKoFarLZ/QALXfFY+nT4KDq6rB16mqMGDrgxsaNdbmrMmnVY4dOxYlJSVISEiAVqtFaGgo0tLSLCYLRERE1mBJQpomTxgAIDY2liUIIiKiZqxZJAxERESNTer7IOQ+rZIJAxERyQJLEtJwpCARERFZxB4GIiKSBfYwSMOEgYiIZIEJgzQsSRAREZFF7GEgIiJZYA+DNEwYiIhIFgRImxrZpMsiNwNMGIiISBbYwyANxzAQERGRRexhICIiWWAPgzRMGIiISBaYMEjDkgQRERFZxB4GIiKSBfYwSMOEgYiIZEEQFBAkfOlLObc1YEmCiIiILGIPAxERyYIJCkkLN0k5tzVgwkBERLLAMQzSsCRBREREFrGHgYiIZIGDHqVhwkBERLLAkoQ0TBiIiEgW2MMgDccwEBERkUXsYSAiIlkQJJYk5N7DwISBiIhkQQAgCNLOlzOWJIiIiMgi9jAQEZEsmKCAgis9NhgTBiIikgXOkpCGJQkiIiKyiD0MREQkCyZBAQUXbmowJgxERCQLgiBxloTMp0mwJEFEREQWsYeBiIhkgYMepWEPAxERyUJtwiBls0ZSUhLuvvtuuLu7w8vLC6NGjUJubq5Zm8rKSsTExKBt27Zwc3PDmDFjUFxcbNamoKAAI0aMgIuLC7y8vDBnzhxUV1ebtdmzZw/69u0LR0dHBAYGIjk5uU48a9asQZcuXeDk5ITw8HAcOnTIqudhwkBERLJQ+7ZKKZs19u7di5iYGBw8eBDp6emoqqrCsGHDUFFRIbaJi4vD9u3b8cknn2Dv3r0oLCzE6NGjxeNGoxEjRoyAwWDAgQMHsHHjRiQnJyMhIUFsk5+fjxEjRmDIkCHIzs7GrFmzMHXqVOzatUtss3nzZsTHx2PhwoU4cuQI+vTpg6ioKFy4cKHez6MQhJY7jEOn00Gj0eDyqa5QuzP3odYp5J3nmzoEokZj1Fcid9UrKCsrg1qtbpR71H5X9EiZDzsXxwZfx3hVj9yn3mpwrCUlJfDy8sLevXsxaNAglJWVoX379khJScETTzwBAMjJyUFQUBAyMzMxYMAAfPXVV3jkkUdQWFgIb29vAMC6deswb948lJSUQKVSYd68edixYweOHz8u3mvcuHEoLS1FWloaACA8PBx33303Vq9eDQAwmUzw9/fHzJkzMX/+/HrFz29ZIiKShdpZElI2oCYBuXHT6/X1un9ZWRkAwNPTEwCQlZWFqqoqREZGim169uyJTp06ITMzEwCQmZmJkJAQMVkAgKioKOh0Opw4cUJsc+M1atvUXsNgMCArK8usjVKpRGRkpNimPpgwEBGRLNR86UsZw1BzHX9/f2g0GnFLSkqyeG+TyYRZs2bh3nvvRa9evQAAWq0WKpUKHh4eZm29vb2h1WrFNjcmC7XHa4/dqo1Op8O1a9dw8eJFGI3Gm7apvUZ9cJYEERGRFc6ePWtWknB0tFzmiImJwfHjx7F///7GDK1RMWEgIiJZsNW0SrVabdUYhtjYWKSmpmLfvn3w8/MT9/v4+MBgMKC0tNSsl6G4uBg+Pj5im7/OZqidRXFjm7/OrCguLoZarYazszPs7OxgZ2d30za116gPliSIiEgWBBtsVt1PEBAbG4utW7di9+7dCAgIMDseFhYGBwcHZGRkiPtyc3NRUFCAiIgIAEBERASOHTtmNpshPT0darUawcHBYpsbr1HbpvYaKpUKYWFhZm1MJhMyMjLENvXBHgYiIqJGEBMTg5SUFHzxxRdwd3cXxwtoNBo4OztDo9FgypQpiI+Ph6enJ9RqNWbOnImIiAgMGDAAADBs2DAEBwfjmWeewdKlS6HVarFgwQLExMSIpZDp06dj9erVmDt3LiZPnozdu3djy5Yt2LFjhxhLfHw8oqOj0a9fP/Tv3x8rVqxARUUFJk2aVO/nYcJARESycLtXely7di0AYPDgwWb7N2zYgIkTJwIAli9fDqVSiTFjxkCv1yMqKgrvvfee2NbOzg6pqamYMWMGIiIi4OrqiujoaCxevFhsExAQgB07diAuLg4rV66En58f1q9fj6ioKLHN2LFjUVJSgoSEBGi1WoSGhiItLa3OQMhb4ToMRM0c12Gg1ux2rsPQdeMrsHNxavB1jFcr8Vv0m40aa3PGHgYiIpIHiT0M4LskiIiIiG6NPQxERCQLN67W2NDz5YwJAxERyQJfby0NSxJERERkEXsYiIhIHgSFtIGLMu9hYMJARESywDEM0rAkQURERBaxh4GIiOShIS+E+Ov5MsaEgYiIZIGzJKSpV8Lw5Zdf1vuCjz32WIODISIiouapXgnDqFGj6nUxhUIBo9EoJR4iIqLGI/OyghT1ShhMJlNjx0FERNSoWJKQRtIsicrKSlvFQURE1LgEG2wyZnXCYDQasWTJEnTs2BFubm747bffAACvvfYaPvjgA5sHSERERE3P6oThjTfeQHJyMpYuXQqVSiXu79WrF9avX2/T4IiIiGxHYYNNvqxOGD766CP8+9//xoQJE2BnZyfu79OnD3JycmwaHBERkc2wJCGJ1QnD+fPnERgYWGe/yWRCVVWVTYIiIiKi5sXqhCE4OBjfffddnf2ffvop7rrrLpsERUREZHPsYZDE6pUeExISEB0djfPnz8NkMuHzzz9Hbm4uPvroI6SmpjZGjERERNLxbZWSWN3DMHLkSGzfvh3ffPMNXF1dkZCQgJMnT2L79u148MEHGyNGIiIiamINepfEwIEDkZ6ebutYiIiIGg1fby1Ng18+dfjwYZw8eRJAzbiGsLAwmwVFRERkc3xbpSRWJwznzp3D+PHj8f3338PDwwMAUFpainvuuQcff/wx/Pz8bB0jERERNTGrxzBMnToVVVVVOHnyJC5duoRLly7h5MmTMJlMmDp1amPESEREJF3toEcpm4xZ3cOwd+9eHDhwAD169BD39ejRA++++y4GDhxo0+CIiIhsRSHUbFLOlzOrEwZ/f/+bLtBkNBrh6+trk6CIiIhsjmMYJLG6JLFs2TLMnDkThw8fFvcdPnwYL774Iv71r3/ZNDgiIiJqHurVw9CmTRsoFNdrNxUVFQgPD4e9fc3p1dXVsLe3x+TJkzFq1KhGCZSIiEgSLtwkSb0ShhUrVjRyGERERI2MJQlJ6pUwREdHN3YcRERE1Iw1eOEmAKisrITBYDDbp1arJQVERETUKNjDIInVgx4rKioQGxsLLy8vuLq6ok2bNmYbERFRs8S3VUpidcIwd+5c7N69G2vXroWjoyPWr1+PRYsWwdfXFx999FFjxEhERERNzOqSxPbt2/HRRx9h8ODBmDRpEgYOHIjAwEB07twZmzZtwoQJExojTiIiImk4S0ISq3sYLl26hK5duwKoGa9w6dIlAMB9992Hffv22TY6IiIiG6ld6VHKJmdWJwxdu3ZFfn4+AKBnz57YsmULgJqeh9qXUREREVHrYnXCMGnSJPz8888AgPnz52PNmjVwcnJCXFwc5syZY/MAiYiIbIKDHiWxegxDXFyc+N+RkZHIyclBVlYWAgMD0bt3b5sGR0RERM2DpHUYAKBz587o3LmzLWIhIiJqNApIfFulzSJpmeqVMKxatareF3zhhRcaHAwRERE1T/VKGJYvX16viykUiiZJGB7vHgJ7hcNtvy/R7eDfvbipQyBqNNVGPXJv1804rVKSeiUMtbMiiIiIWiwuDS2J1bMkiIiISH4kD3okIiJqEdjDIAkTBiIikgWpqzVypUciIiIiC9jDQERE8sCShCQN6mH47rvv8PTTTyMiIgLnz58HAPz3v//F/v37bRocERGRzXBpaEmsThg+++wzREVFwdnZGT/99BP0ej0AoKysDG+++abNAyQiIqKmZ3XC8Prrr2PdunX4z3/+AweH64sl3XvvvThy5IhNgyMiIrIVvt5aGqvHMOTm5mLQoEF19ms0GpSWltoiJiIiItvjSo+SWN3D4OPjg7y8vDr79+/fj65du9okKCIiIpvjGAZJrE4Ypk2bhhdffBE//PADFAoFCgsLsWnTJsyePRszZsxojBiJiIhanH379uHRRx+Fr68vFAoFtm3bZnZ84sSJUCgUZtvw4cPN2ly6dAkTJkyAWq2Gh4cHpkyZgvLycrM2R48excCBA+Hk5AR/f38sXbq0TiyffPIJevbsCScnJ4SEhGDnzp1WP4/VJYn58+fDZDJh6NChuHr1KgYNGgRHR0fMnj0bM2fOtDoAIiKi2+F2L9xUUVGBPn36YPLkyRg9evRN2wwfPhwbNmwQPzs6OpodnzBhAoqKipCeno6qqipMmjQJzz33HFJSUgAAOp0Ow4YNQ2RkJNatW4djx45h8uTJ8PDwwHPPPQcAOHDgAMaPH4+kpCQ88sgjSElJwahRo3DkyBH06tXLiucXhAb98xkMBuTl5aG8vBzBwcFwc3NryGUk0el00Gg0GIyRfFsltVp23bs1dQhEjabaqEdG3gqUlZVBrVY3yj1qvyu6JrwJpZNTg69jqqzEb4tfaVCsCoUCW7duxahRo8R9EydORGlpaZ2eh1onT55EcHAwfvzxR/Tr1w8AkJaWhocffhjnzp2Dr68v1q5di1dffRVarRYqlQpAzR/227ZtQ05ODgBg7NixqKioQGpqqnjtAQMGIDQ0FOvWrav3MzR4pUeVSoXg4GD079+/SZIFIiKipqDT6cy22uUFGmLPnj3w8vJCjx49MGPGDPzxxx/isczMTHh4eIjJAgBERkZCqVTihx9+ENsMGjRITBYAICoqCrm5ubh8+bLYJjIy0uy+UVFRyMzMtCpWq0sSQ4YMgULx9yNFd+/ebe0liYiIGp/UqZF/nuvv72+2e+HChUhMTLT6csOHD8fo0aMREBCA06dP45VXXsFDDz2EzMxM2NnZQavVwsvLy+wce3t7eHp6QqvVAgC0Wi0CAgLM2nh7e4vH2rRpA61WK+67sU3tNerL6oQhNDTU7HNVVRWys7Nx/PhxREdHW3s5IiKi28NGS0OfPXvWrCTx13EH9TVu3Djxv0NCQtC7d29069YNe/bswdChQyUE2jisThiWL19+0/2JiYl1Rm4SERG1Nmq1ulHGW3Tt2hXt2rVDXl4ehg4dCh8fH1y4cMGsTXV1NS5dugQfHx8ANUsdFBcXm7Wp/WypTe3x+rLZ2yqffvppfPjhh7a6HBERkW0183UYzp07hz/++AMdOnQAAERERKC0tBRZWVlim927d8NkMiE8PFxss2/fPlRVVYlt0tPT0aNHD7Rp00Zsk5GRYXav9PR0REREWBWfzRKGzMxMOEkYfUpERNSYbvfS0OXl5cjOzkZ2djYAID8/H9nZ2SgoKEB5eTnmzJmDgwcP4syZM8jIyMDIkSMRGBiIqKgoAEBQUBCGDx+OadOm4dChQ/j+++8RGxuLcePGwdfXFwDw1FNPQaVSYcqUKThx4gQ2b96MlStXIj4+XozjxRdfRFpaGt5++23k5OQgMTERhw8fRmxsrFXPY3VJ4q9zSQVBQFFREQ4fPozXXnvN2ssRERG1SocPH8aQIUPEz7Vf4tHR0Vi7di2OHj2KjRs3orS0FL6+vhg2bBiWLFliNiZi06ZNiI2NxdChQ6FUKjFmzBisWrVKPK7RaPD1118jJiYGYWFhaNeuHRISEsQ1GADgnnvuQUpKChYsWIBXXnkFd9xxB7Zt22bVGgxAA9ZhmDRpktlnpVKJ9u3b44EHHsCwYcOsurlUXIeB5IDrMFBrdjvXYej2ypuwk9ATbqysxOk3G7YOQ2tgVQ+D0WjEpEmTEBISItZGiIiIWgQbzZKQK6vGMNjZ2WHYsGF8KyUREbU4fL21NFYPeuzVqxd+++23xoiFiIiImimrE4bXX38ds2fPRmpqKoqKiuoskUlERNRsNdMplS1BvccwLF68GC+99BIefvhhAMBjjz1mtkS0IAhQKBQwGo22j5KIiEgqjmGQpN4Jw6JFizB9+nR8++23jRkPERERNUP1ThhqZ1/ef//9jRYMERFRY5E6cFHugx6tmlZ5q7dUEhERNWssSUhiVcLQvXt3i0nDpUuXJAVEREREzY9VCcOiRYug0WgaKxYiIqJGw5KENFYlDOPGjYOXl1djxUJERNR4WJKQpN7rMHD8AhERkXxZPUuCiIioRWIPgyT1ThhMJlNjxkFERNSoOIZBGqvGMBAREbVY7GGQxOp3SRAREZH8sIeBiIjkgT0MkjBhICIiWeAYBmlYkiAiIiKL2MNARETywJKEJEwYiIhIFliSkIYlCSIiIrKIPQxERCQPLElIwoSBiIjkgQmDJCxJEBERkUXsYSAiIllQ/LlJOV/OmDAQEZE8sCQhCRMGIiKSBU6rlIZjGIiIiMgi9jAQEZE8sCQhCRMGIiKSD5l/6UvBkgQRERFZxB4GIiKSBQ56lIYJAxERyQPHMEjCkgQRERFZxB4GIiKSBZYkpGHCQERE8sCShCQsSRAREZFF7GEgIiJZYElCGiYMREQkDyxJSMKEgYiI5IEJgyQcw0BEREQWsYeBiIhkgWMYpGHCQERE8sCShCQsSRAREZFF7GEgIiJZUAgCFELDuwmknNsaMGEgIiJ5YElCEpYkiIiIyCL2MBARkSxwloQ0TBiIiEgeWJKQhCUJIiIisog9DEREJAssSUjDhIGIiOSBJQlJmDAQEZEssIdBGo5hICIiagT79u3Do48+Cl9fXygUCmzbts3suCAISEhIQIcOHeDs7IzIyEj8+uuvZm0uXbqECRMmQK1Ww8PDA1OmTEF5eblZm6NHj2LgwIFwcnKCv78/li5dWieWTz75BD179oSTkxNCQkKwc+dOq5+HCQMREcmDYIPNChUVFejTpw/WrFlz0+NLly7FqlWrsG7dOvzwww9wdXVFVFQUKisrxTYTJkzAiRMnkJ6ejtTUVOzbtw/PPfeceFyn02HYsGHo3LkzsrKysGzZMiQmJuLf//632ObAgQMYP348pkyZgp9++gmjRo3CqFGjcPz4caueRyEILXetS51OB41Gg8EYCXuFQ1OHQ9Qo7Lp3a+oQiBpNtVGPjLwVKCsrg1qtbpR71H5XhD35BuwdnBp8neqqSmRtebVBsSoUCmzduhWjRo0CUNO74Ovri5deegmzZ88GAJSVlcHb2xvJyckYN24cTp48ieDgYPz444/o168fACAtLQ0PP/wwzp07B19fX6xduxavvvoqtFotVCoVAGD+/PnYtm0bcnJyAABjx45FRUUFUlNTxXgGDBiA0NBQrFu3rt7PwB4GIiIiK+h0OrNNr9dbfY38/HxotVpERkaK+zQaDcLDw5GZmQkAyMzMhIeHh5gsAEBkZCSUSiV++OEHsc2gQYPEZAEAoqKikJubi8uXL4ttbrxPbZva+9QXEwYiIpIHQZC+AfD394dGoxG3pKQkq0PRarUAAG9vb7P93t7e4jGtVgsvLy+z4/b29vD09DRrc7Nr3HiPv2tTe7y+OEuCiIhkwVazJM6ePWtWknB0dJQYWcvAHgYiIiIrqNVqs60hCYOPjw8AoLi42Gx/cXGxeMzHxwcXLlwwO15dXY1Lly6ZtbnZNW68x9+1qT1eX0wYiIhIHm7zLIlbCQgIgI+PDzIyMsR9Op0OP/zwAyIiIgAAERERKC0tRVZWlthm9+7dMJlMCA8PF9vs27cPVVVVYpv09HT06NEDbdq0EdvceJ/aNrX3qS8mDEREJAsKk/TNGuXl5cjOzkZ2djaAmoGO2dnZKCgogEKhwKxZs/D666/jyy+/xLFjx/Dss8/C19dXnEkRFBSE4cOHY9q0aTh06BC+//57xMbGYty4cfD19QUAPPXUU1CpVJgyZQpOnDiBzZs3Y+XKlYiPjxfjePHFF5GWloa3334bOTk5SExMxOHDhxEbG2vV83AMAxERUSM4fPgwhgwZIn6u/RKPjo5GcnIy5s6di4qKCjz33HMoLS3Ffffdh7S0NDg5XZ/6uWnTJsTGxmLo0KFQKpUYM2YMVq1aJR7XaDT4+uuvERMTg7CwMLRr1w4JCQlmazXcc889SElJwYIFC/DKK6/gjjvuwLZt29CrVy+rnofrMMhMr/By/OP5EtwRchVtfaqROLkLMtM04nGPdlWY8moRwu6/AleNEccPumHNgo4ozK+p0bl7VOOZ2Vr0vb8cXr4GlF2yx4E0DTYu9cHVK3biddp3NGBm0jn0ubcclRV2SP+kDT58swNMRsVtf+aWjuswWGfCxF8wYWKO2b6zBW7457PDAADDH8nH4MizCLyjFC6u1fjHI4+golx1s0vB3sGI5Wv3oFtgGWKnPoDf8jzEYwMHn8OTT+eio185dKUqbN/aDZ9t7t5oz9Va3c51GO4e9brkdRh+3LagUWNtztjDIDNOLib8dsIJu/7niYUfnvnLUQELPzwDY7UCiZMCcLVcidHPleCtzacx7f4e0F+zg6d3Fdp6V+M/izug4JQTvPwMeOGtc2jrXYXXn+sCAFAqBSz5KB+XS+wR99gd8PSqwpxVBTBWKbDhrQ63+5FJhs7kq/HqS/eJn403JKqOTkZkHfJG1iFvTHruxC2vM+Wfx3HpohO6BZaZ7e/XX4s5C37EulV9cORHb/h31uGF2T9Bb7BD6lYmeM0V3yUhTZOOYbC0zjbZ3uFv1di4tAMO3NCrUKtjVwOC+13Fu/P9cOpnF5w77YR35/vB0UnAkMdLAQC/5zpjybQu+CFdg6LfHfHz9+5I/n8dEP6gDkq7mv839b3/Cjp1r8T/i+2E30444/C3any01AePTrwIewcri4BEDWA0KnD5kpO46cquj2L/4tNAfJLSAzm/eN7yGv36a3HX3Rewfm1InWMPDCtA5n5f7PyyK7RFrvjxYAds2dQD/xh/CrJ/pWFzZqN1GOSqSRMGS+ts0+3loKr5Mjfor/81JggKVBkUuPPuir89z1VtxNVypVhuCO53FWdynFB68XqZ6PAed7iqTejco/LvLkNkMx07luO/n+7EBylpmPPqj2jvddWq8z3aVOKFOUfw9pv9oNfb1Tnu4GBClcH816fBoER7r2vw8rHuXkQtRZMmDA899BBef/11PP744/Vqr9fr6yzJSbZzNs8JxeccMPnlIrhpqmHvYMKTMRfQ3rcKnt5VNz1H7VmNp2YV46v/ayvua9O+CpdLzKtdtclDm/bVjfcARAByf/HEO2+F4bW592LN8rvg3aECy1bthbPzzX+G6xIQPz8LO7/sil9z29y0RdaP3rhnYCH69L0AhUJAR78rePzJPACApyeT4uaqtiQhZZOzFjWGISkpCYsWLWrqMFotY7UCi6d0Qfw7Z/HZyRMwVgM/feeOQxnuUNxkrKKLmxFLPspHwSkn/Pdt6xYAIWoshw9d/1k885sGuSfbIPnjNAwcch5f7+xi8fzHRp+Gs0s1tmzq8bdt0lK7oINvBRKTDsDeXsDVCnt88Vkgnp50EoLAgb3NltS1FJgwtBwvv/yy2dxSnU4Hf3//Joyo9ck75oLnH+wBF3cjHBwElF2yx8rUX3HqqLNZO2dXI95I+Q3XKpRYNKULjNXXf0leLnFAj7vMu2U92lX9eaxF/chRK1BRrsL5c27w7Vher/Z9+pagZ/Af+CJ9m9n+le9/i2/T/fHOW/0AKLDh372wcf2daONZibJSR4T2rVmRr6jQ1cZPQNQ8tKjf3o6OjrJZs7up1U6R9A3Q444+V7Fx2fW/2lzcapKFKoMCCycGoEpvXtn65bALxr1QDE3bKpT9UVOK6DuoHBU6JQpONXxKE1FDODlXo4NvBXZ/Xb+fvXWr+uCjD4LFz55tK/HGv77HW4v6I+ekeYnCZFLgj4s1yfT9Q8/hl+OeZgMsqXnhLAlpWlTCQNI5uRjhG2AQP/v4G9D1zmu4UmqHkvMqDHykFGV/2OPCeQcEBFVi+uLzyEzT4MhedwA1ycKb//sNjs4mLJ3ZBS5uRri4GQEAZX/Yw2RS4MhedxSccsLcdwvwweu+aNO+ChPnabE9uV2dgWJEtjZlxjH8cMAHF4pd0LZtJZ6edBImkwJ7Mmp6I9t4VqKNZ6XY49AlQIdr1+xxodgF5VdUKLngYna9a9dqfk0WFbrij5KaY2qNHvfdfx5Hs9tDpTLiweG/477B5zDvxUG38UnJalJnOsh8lgQTBpnp3ucaln12Wvw8fVEhAODrzW3wdlwneHpX4Z+JhfBoV41LF+zxzSdtkLLi+mtRA0OuISisptyQnGm+OM6z/YNQfE4Fk0mBhGcDMPOtc1i+/VdUXlXim088zXopiBpLu/bXMO+1H6FWG1BWpsKJY+0Q9/xg8S//hx/7zWxhp2Xv7gMAvPNWGL5J61zv+wyNKsCUGcegAHDyF0/MnzUIp3JuPVWTqCVr0pUey8vLkZdXM7L4rrvuwjvvvIMhQ4bA09MTnTp1sng+V3okOeBKj9Sa3c6VHiMeWix5pcfMrxK40mNTsLTONhERkc1wloQkTZowDB48GC34VRZERESywTEMREQkC5wlIQ0TBiIikgeTULNJOV/GmDAQEZE8cAyDJJwUT0RERBaxh4GIiGRBAYljGGwWScvEhIGIiOSBKz1KwpIEERERWcQeBiIikgVOq5SGCQMREckDZ0lIwpIEERERWcQeBiIikgWFIEAhYeCilHNbAyYMREQkD6Y/NynnyxhLEkRERGQRexiIiEgWWJKQhgkDERHJA2dJSMKEgYiI5IErPUrCMQxERERkEXsYiIhIFrjSozRMGIiISB5YkpCEJQkiIiKyiD0MREQkCwpTzSblfDljwkBERPLAkoQkLEkQERGRRexhICIieeDCTZIwYSAiIlng0tDSsCRBREREFrGHgYiI5IGDHiVhwkBERPIgAJAyNVLe+QITBiIikgeOYZCGYxiIiIjIIvYwEBGRPAiQOIbBZpG0SEwYiIhIHjjoURKWJIiIiMgi9jAQEZE8mAAoJJ4vY0wYiIhIFjhLQhqWJIiIiMgi9jAQEZE8cNCjJEwYiIhIHpgwSMKSBBEREVnEHgYiIpIH9jBIwoSBiIjkgdMqJWFJgoiIZKF2WqWUzRqJiYlQKBRmW8+ePcXjlZWViImJQdu2beHm5oYxY8aguLjY7BoFBQUYMWIEXFxc4OXlhTlz5qC6utqszZ49e9C3b184OjoiMDAQycnJDf43uhUmDERERI3kzjvvRFFRkbjt379fPBYXF4ft27fjk08+wd69e1FYWIjRo0eLx41GI0aMGAGDwYADBw5g48aNSE5ORkJCgtgmPz8fI0aMwJAhQ5CdnY1Zs2Zh6tSp2LVrl82fhSUJIiKShyYYw2Bvbw8fH586+8vKyvDBBx8gJSUFDzzwAABgw4YNCAoKwsGDBzFgwAB8/fXX+OWXX/DNN9/A29sboaGhWLJkCebNm4fExESoVCqsW7cOAQEBePvttwEAQUFB2L9/P5YvX46oqKiGP+tNsIeBiIjkwSRI3wDodDqzTa/X/+0tf/31V/j6+qJr166YMGECCgoKAABZWVmoqqpCZGSk2LZnz57o1KkTMjMzAQCZmZkICQmBt7e32CYqKgo6nQ4nTpwQ29x4jdo2tdewJSYMREREVvD394dGoxG3pKSkm7YLDw9HcnIy0tLSsHbtWuTn52PgwIG4cuUKtFotVCoVPDw8zM7x9vaGVqsFAGi1WrNkofZ47bFbtdHpdLh27ZotHlfEkgQREcmDjUoSZ8+ehVqtFnc7OjretPlDDz0k/nfv3r0RHh6Ozp07Y8uWLXB2dm54HE2EPQxERCQTwvWkoSEbahIGtVpttv1dwvBXHh4e6N69O/Ly8uDj4wODwYDS0lKzNsXFxeKYBx8fnzqzJmo/W2qjVqttnpQwYSAiIroNysvLcfr0aXTo0AFhYWFwcHBARkaGeDw3NxcFBQWIiIgAAERERODYsWO4cOGC2CY9PR1qtRrBwcFimxuvUdum9hq2xISBiIjkQUrvQgPKGbNnz8bevXtx5swZHDhwAI8//jjs7Owwfvx4aDQaTJkyBfHx8fj222+RlZWFSZMmISIiAgMGDAAADBs2DMHBwXjmmWfw888/Y9euXViwYAFiYmLEXo3p06fjt99+w9y5c5GTk4P33nsPW7ZsQVxcnM3/+TiGgYiI5MF0vazQ8PPr79y5cxg/fjz++OMPtG/fHvfddx8OHjyI9u3bAwCWL18OpVKJMWPGQK/XIyoqCu+99554vp2dHVJTUzFjxgxERETA1dUV0dHRWLx4sdgmICAAO3bsQFxcHFauXAk/Pz+sX7/e5lMqAUAhCC13cWydTgeNRoPBGAl7hUNTh0PUKOy6d2vqEIgaTbVRj4y8FSgrKzMbSGhLtd8VkZ1jYa+s33iDm6k26fHN76sbNdbmjD0MREQkD4KpZpNyvowxYSAiInng2yolYcJARETycJvHMLQ2nCVBREREFrGHgYiI5IElCUmYMBARkTwIkJgw2CySFoklCSIiIrKIPQxERCQPLElIwoSBiIjkwWQCIGEtBZO812FgSYKIiIgsYg8DERHJA0sSkjBhICIieWDCIAlLEkRERGQRexiIiEgeuDS0JEwYiIhIFgTBBEHCGyelnNsaMGEgIiJ5EARpvQQcw0BERER0a+xhICIieRAkjmGQeQ8DEwYiIpIHkwlQSBiHIPMxDCxJEBERkUXsYSAiInlgSUISJgxERCQLgskEQUJJQu7TKlmSICIiIovYw0BERPLAkoQkTBiIiEgeTAKgYMLQUCxJEBERkUXsYSAiInkQBABS1mGQdw8DEwYiIpIFwSRAkFCSEJgwEBERyYBggrQeBk6rJCIiIrol9jAQEZEssCQhDRMGIiKSB5YkJGnRCUNttleNKklrcRA1Z4JR39QhEDWaalPNz/ft+Otd6ndFNapsF0wL1KIThitXrgAA9mNnE0dC1IjymjoAosZ35coVaDSaRrm2SqWCj48P9mulf1f4+PhApVLZIKqWRyG04KKMyWRCYWEh3N3doVAomjocWdDpdPD398fZs2ehVqubOhwim+LP9+0nCAKuXLkCX19fKJWNNw6/srISBoNB8nVUKhWcnJxsEFHL06J7GJRKJfz8/Jo6DFlSq9X8hUqtFn++b6/G6lm4kZOTk2y/6G2F0yqJiIjIIiYMREREZBETBrKKo6MjFi5cCEdHx6YOhcjm+PNN9Pda9KBHIiIiuj3Yw0BEREQWMWEgIiIii5gwEBERkUVMGIiIiMgiJgxUb2vWrEGXLl3g5OSE8PBwHDp0qKlDIrKJffv24dFHH4Wvry8UCgW2bdvW1CERNTtMGKheNm/ejPj4eCxcuBBHjhxBnz59EBUVhQsXLjR1aESSVVRUoE+fPlizZk1Th0LUbHFaJdVLeHg47r77bqxevRpAzXs8/P39MXPmTMyfP7+JoyOyHYVCga1bt2LUqFFNHQpRs8IeBrLIYDAgKysLkZGR4j6lUonIyEhkZmY2YWRERHS7MGEgiy5evAij0Qhvb2+z/d7e3tBqtU0UFRER3U5MGIiIiMgiJgxkUbt27WBnZ4fi4mKz/cXFxfDx8WmiqIiI6HZiwkAWqVQqhIWFISMjQ9xnMpmQkZGBiIiIJoyMiIhuF/umDoBahvj4eERHR6Nfv37o378/VqxYgYqKCkyaNKmpQyOSrLy8HHl5eeLn/Px8ZGdnw9PTE506dWrCyIiaD06rpHpbvXo1li1bBq1Wi9DQUKxatQrh4eFNHRaRZHv27MGQIUPq7I+OjkZycvLtD4ioGWLCQERERBZxDAMRERFZxISBiIiILGLCQERERBYxYSAiIiKLmDAQERGRRUwYiIiIyCImDERERGQREwYiIiKyiAkDkUQTJ07EqFGjxM+DBw/GrFmzbnsce/bsgUKhQGlp6d+2USgU2LZtW72vmZiYiNDQUElxnTlzBgqFAtnZ2ZKuQ0RNiwkDtUoTJ06EQqGAQqGASqVCYGAgFi9ejOrq6ka/9+eff44lS5bUq219vuSJiJoDvnyKWq3hw4djw4YN0Ov12LlzJ2JiYuDg4ICXX365TluDwQCVSmWT+3p6etrkOkREzQl7GKjVcnR0hI+PDzp37owZM2YgMjISX375JYDrZYQ33ngDvr6+6NGjBwDg7NmzePLJJ+Hh4QFPT0+MHDkSZ86cEa9pNBoRHx8PDw8PtG3bFnPnzsVfX8fy15KEXq/HvHnz4O/vD0dHRwQGBuKDDz7AmTNnxBcetWnTBgqFAhMnTgRQ8/rwpKQkBAQEwNnZGX369MGnn35qdp+dO3eie/fucHZ2xpAhQ8zirK958+ahe/fucHFxQdeuXfHaa6+hqqqqTrv3338f/v7+cHFxwZNPPomysjKz4+vXr0dQUBCcnJzQs2dPvPfee1bHQkTNGxMGkg1nZ2cYDAbxc0ZGBnJzc5Geno7U1FRUVVUhKioK7u7u+O677/D999/Dzc0Nw4cPF897++23kZycjA8//BD79+/HpUuXsHXr1lve99lnn8X//vc/rFq1CidPnsT7778PNzc3+Pv747PPPgMA5ObmoqioCCtXrgQAJCUl4aOPPsK6detw4sQJxMXF4emnn8bevXsB1CQ2o0ePxqOPPors7GxMnToV8+fPt/rfxN3dHcnJyfjll1+wcuVK/Oc//8Hy5cvN2uTl5WHLli3Yvn070tLS8NNPP+H5558Xj2/atAkJCQl44403cPLkSbz55pt47bXXsHHjRqvjIaJmTCBqhaKjo4WRI0cKgiAIJpNJSE9PFxwdHYXZs2eLx729vQW9Xi+e89///lfo0aOHYDKZxH16vV5wdnYWdu3aJQiCIHTo0EFYunSpeLyqqkrw8/MT7yUIgnD//fcLL774oiAIgpCbmysAENLT028a57fffisAEC5fvizuq6ysFFxcXIQDBw6YtZ0yZYowfvx4QRAE4eWXXxaCg4PNjs+bN6/Otf4KgLB169a/Pb5s2TIhLCxM/Lxw4ULBzs5OOHfunLjvq6++EpRKpVBUVCQIgiB069ZNSElJMbvOkiVLhIiICEEQBCE/P18AIPz0009/e18iav44hoFardTUVLi5uaGqqgomkwlPPfUUEhMTxeMhISFm4xZ+/vln5OXlwd3d3ew6lZWVOH36NMrKylBUVITw8HDxmL29Pfr161enLFErOzsbdnZ2uP/+++sdd15eHq5evYoHH3zQbL/BYMBdd90FADh58qRZHAAQERFR73vU2rx5M1atWoXTp0+jvLwc1dXVUKvVZm06deqEjh07mt3HZDIhNzcX7u7uOH36NKZMmYJp06aJbaqrq6HRaKyOh4iaLyYM1GoNGTIEa9euhUqlgq+vL+ztzX/cXV1dzT6Xl5cjLCwMmzZtqnOt9u3bNygGZ2dnq88pLy8HAOzYscPsixqoGZdhK5mZmZgwYQIWLVqEqKgoaDQafPzxx3j77betjvU///lPnQTGzs7OZrESUdNjwkCtlqurKwIDA+vdvm/fvti8eTO8vLzq/JVdq0OHDvjhhx8waNAgADV/SWdlZaFv3743bR8SEgKTyYS9e/ciMjKyzvHaHg6j0SjuCw4OhqOjIwoKCv62ZyIoKEgcwFnr4MGDlh/yBgcOHEDnzp3x6quvivt+//33Ou0KCgpQWFgIX19f8T5KpRI9evSAt7c3fH198dtvv2HChAlW3Z+IWhYOeiT604QJE9CuXTuMHDkS3333HfLz87Fnzx688MILOHfuHADgxRdfxFtvvYVt27YhJycHzz///C3XUOjSpQuio6MxefJkbNu2Tbzmli1bAACdO3eGQqFAamoqSkpKUF5eDnd3d8yePRtxcXHYuHEjTp8+jSNHjuDdd98VBxJOnz4dv/76K+bMmYPc3FykpKQgOTnZque94447UFBQgI8//hinT5/GqlWrbjqA08nJCdHR0fj555/x3Xff4YUXXsCTTz4JHx8fAMCiRYuQlJSEVatW4dSpUzh27Bg2bNiAd955x6p4iKh5Y8JA9CcXFxfs27cPnTp1wujRoxEUFIQpU6agsrJS7HF46aWX8MwzzyA6OhoRERFwd3fH448/fsvrrl27Fk888QSef/559OzZE9OmTUNFRQUAoGPHjli0aBHmz58Pb29vxMbGAgCWLFmC1157DUlJSQgKCsLw4cOxY8cOBAQEAKgZV/DZZ59h27Zt6NOnD9atW4c333zTqud97LHHEBcXh9jYWISGhuLAgQN47bXX6rQLDAzE6NGj8fDDD2PYsGHo3bu32bTJqVOnYv369diwYQNCQkJw//33Izk5WYyViFoHhfB3o7WIiIiI/sQeBiIiIrKICQMRERFZxISBiIiILGLCQERERBYxYSAiIiKLmDAQERGRRUwYiIiIyCImDERERGQREwYiIiKyiAkDERERWcSEgYiIiCz6/+XzPqAntauMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to the training and testing data\n",
    "Training_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Train%20Dataset%20(Clustered%20%2B%20Feature%20Engineering%20%2B%20SMOTEENN).csv\"\n",
    "Testing_Data_Path = \"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Untouched%20Test%20Data.csv\"\n",
    "\n",
    "# Read the train and test data files\n",
    "df = pd.read_csv(Training_Data_Path)\n",
    "test_df = pd.read_csv(Testing_Data_Path)\n",
    "\n",
    "# Feature engineering\n",
    "df['NotOverweight'] = df['BMI'].apply(lambda x: 0 if x >= 25 else 1)\n",
    "test_df['NotOverweight'] = test_df['BMI'].apply(lambda x: 0 if x >= 25 else 1)\n",
    "\n",
    "# Select the specific columns for training\n",
    "X_train = df[['PhysicalCondition', 'LackOfDisease', 'Age', 'Income', 'NotOverweight']]\n",
    "y_train = df['Diabetes_binary']\n",
    "\n",
    "# Select the specific columns for testing\n",
    "X_test = test_df[['PhysicalCondition', 'LackOfDisease', 'Age', 'Income', 'NotOverweight']]\n",
    "y_test = test_df['Diabetes_binary']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 4]\n",
    "}\n",
    "\n",
    "# Initialize and train XGBoost with GPU support\n",
    "xgb_model = XGBClassifier(eval_metric='logloss', tree_method='hist', device='cuda')\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best model and parameters\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "best_params = grid_search_xgb.best_params_\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred = best_xgb_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(report)\n",
    "\n",
    "# Display summary table using pandas\n",
    "summary_df = pd.DataFrame({'Accuracy': [accuracy], 'Best Parameters': [str(best_params)]})\n",
    "print(summary_df)\n",
    "\n",
    "# Display confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(best_xgb_model, X_test_scaled, y_test)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
