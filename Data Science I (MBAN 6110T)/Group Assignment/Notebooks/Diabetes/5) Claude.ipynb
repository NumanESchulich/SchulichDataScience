{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model          MSE       RMSE        MAE        R2  \\\n",
      "0      RandomForest  1101.985776  33.196171  21.086063  0.073111   \n",
      "1  LinearRegression  1818.355418  42.642179  35.704248 -0.529433   \n",
      "2      RandomForest  1256.837138  35.451899  22.302058 -0.057136   \n",
      "3  LinearRegression  1820.241202  42.664285  35.701179 -0.531019   \n",
      "\n",
      "   Feature Engineered  \n",
      "0               False  \n",
      "1               False  \n",
      "2                True  \n",
      "3                True  \n",
      "\n",
      "Predictions using RandomForest without feature engineering:\n",
      "Sample 1: 100.00% chance of diabetes\n",
      "Sample 2: 100.00% chance of diabetes\n",
      "Sample 3: 69.00% chance of diabetes\n",
      "Sample 4: 100.00% chance of diabetes\n",
      "Sample 5: 100.00% chance of diabetes\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "      feature  importance\n",
      "13    GenHlth    0.282460\n",
      "3         BMI    0.212421\n",
      "18        Age    0.161880\n",
      "0      HighBP    0.084572\n",
      "20     Income    0.049987\n",
      "15   PhysHlth    0.035681\n",
      "19  Education    0.031167\n",
      "14   MentHlth    0.026364\n",
      "1    HighChol    0.016077\n",
      "4      Smoker    0.014102\n",
      "\n",
      "Predictions using LinearRegression without feature engineering:\n",
      "Sample 1: 47.43% chance of diabetes\n",
      "Sample 2: 6.83% chance of diabetes\n",
      "Sample 3: 17.97% chance of diabetes\n",
      "Sample 4: 72.25% chance of diabetes\n",
      "Sample 5: 48.90% chance of diabetes\n",
      "\n",
      "Top 10 Coefficients:\n",
      "                 feature  coefficient\n",
      "13               GenHlth    12.438576\n",
      "18                   Age     8.155100\n",
      "3                    BMI     7.989904\n",
      "0                 HighBP     7.882340\n",
      "1               HighChol     5.256965\n",
      "2              CholCheck     2.826676\n",
      "17                   Sex     2.231234\n",
      "6   HeartDiseaseorAttack     1.197077\n",
      "16              DiffWalk     0.915777\n",
      "5                 Stroke     0.470088\n",
      "\n",
      "Predictions using RandomForest with feature engineering:\n",
      "Sample 1: 100.00% chance of diabetes\n",
      "Sample 2: 100.00% chance of diabetes\n",
      "Sample 3: 67.00% chance of diabetes\n",
      "Sample 4: 100.00% chance of diabetes\n",
      "Sample 5: 100.00% chance of diabetes\n",
      "\n",
      "Top 10 Feature Importances:\n",
      "              feature  importance\n",
      "7             GenHlth    0.306402\n",
      "11                Age    0.170489\n",
      "13             Income    0.086047\n",
      "1                 BMI    0.079969\n",
      "15           NoHighBP    0.058506\n",
      "12          Education    0.033422\n",
      "22          NoDisease    0.031341\n",
      "21  PhysicalCondition    0.029853\n",
      "23          Lifestyle    0.027859\n",
      "10                Sex    0.021300\n",
      "\n",
      "Predictions using LinearRegression with feature engineering:\n",
      "Sample 1: 93111090405.27% chance of diabetes\n",
      "Sample 2: 533289227601.69% chance of diabetes\n",
      "Sample 3: -1987071636682.88% chance of diabetes\n",
      "Sample 4: 443640067421.59% chance of diabetes\n",
      "Sample 5: 917031251447.20% chance of diabetes\n",
      "\n",
      "Top 10 Coefficients:\n",
      "                   feature   coefficient\n",
      "21       PhysicalCondition  1.501183e+12\n",
      "23               Lifestyle  7.861217e+11\n",
      "15                NoHighBP  5.760558e+10\n",
      "16              NoHighChol  5.752627e+10\n",
      "17  NoHeartDiseaseorAttack  3.401240e+10\n",
      "18                NoStroke  2.297028e+10\n",
      "11                     Age  7.490200e+00\n",
      "0                CholCheck  2.864942e+00\n",
      "10                     Sex  2.069429e+00\n",
      "24                NotObese  9.131890e-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Read the data file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/Data%20Science%20I%20(MBAN%206110T)/Group%20Assignment/Datasets/Full%20Dataset%20(RAW).csv\")\n",
    "\n",
    "# Drop the ID column\n",
    "df = df.drop('ID', axis=1)\n",
    "\n",
    "# Modify the target variable\n",
    "df['Diabetes_percentage'] = df['Diabetes_binary'] * 100\n",
    "\n",
    "# Feature Engineering\n",
    "def feature_engineering(df):\n",
    "    # Reverse binary columns\n",
    "    reverse_cols = ['DiffWalk', 'HighBP', 'HighChol', 'HeartDiseaseorAttack', 'Stroke', 'Smoker', 'HvyAlcoholConsump']\n",
    "    for col in reverse_cols:\n",
    "        df[f'No{col}'] = 1 - df[col]\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "    # Clustering\n",
    "    def cluster_column(df, col, bins, labels):\n",
    "        return pd.cut(df[col], bins=bins, labels=labels, include_lowest=True, ordered=False)\n",
    "\n",
    "    df['GenHlth'] = cluster_column(df, 'GenHlth', [0, 1, 2, 3, 4, 5], [0, 0.25, 0.5, 0.75, 1])\n",
    "    df['PhysHlth'] = cluster_column(df, 'PhysHlth', [-1, 6, 12, 18, 24, 30], [1, 0.75, 0.5, 0.25, 0])\n",
    "    df['MentHlth'] = cluster_column(df, 'MentHlth', [-1, 6, 12, 18, 24, 30], [1, 0.75, 0.5, 0.25, 0])\n",
    "    df['BMI'] = cluster_column(df, 'BMI', [0, 18.5, 24.9, 29.9, 39.9, 100], [1, 1, 0.5, 0.25, 0])\n",
    "    df['Income'] = cluster_column(df, 'Income', [0, 2, 4, 5, 7, 8], [0, 0.25, 0.5, 0.75, 1])\n",
    "    df['Education'] = cluster_column(df, 'Education', [0, 2, 3, 4, 5, 6], [0, 0.25, 0.75, 1, 1])\n",
    "    df['Age'] = cluster_column(df, 'Age', [0, 3, 6, 9, 12, 13], [1, 0.75, 0.5, 0.25, 0])\n",
    "\n",
    "    # Convert categorical columns to numeric\n",
    "    cat_columns = df.select_dtypes(include=['category']).columns\n",
    "    for col in cat_columns:\n",
    "        df[col] = df[col].cat.codes\n",
    "\n",
    "    # Feature Engineered Columns\n",
    "    df['PhysicalCondition'] = (df['GenHlth'] + df['NoDiffWalk'] + df['PhysHlth'] + df['PhysActivity']) / 4\n",
    "    df['NoDisease'] = (df['NoHighBP'] + df['NoHighChol'] + df['NoHeartDiseaseorAttack'] + df['NoStroke']) / 4\n",
    "    df['Lifestyle'] = (df['NoSmoker'] + df['NoHvyAlcoholConsump'] + df['Veggies'] + df['Fruits']) / 4\n",
    "    df['NotObese'] = (df['BMI'] < 2).astype(int)  # BMI < 30 corresponds to codes 0 and 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# Prepare data for modeling\n",
    "def prepare_data(df, feature_engineered=True):\n",
    "    if feature_engineered:\n",
    "        df = feature_engineering(df)\n",
    "    \n",
    "    X = df.drop(['Diabetes_binary', 'Diabetes_percentage'], axis=1)\n",
    "    y = df['Diabetes_percentage']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Apply SMOTE to handle class imbalance\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "    \n",
    "    return X_train_resampled, X_test_scaled, y_train_resampled, y_test, X.columns\n",
    "\n",
    "# Train and evaluate model\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, model_name, feature_names):\n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    elif model_name == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }, model, y_pred, feature_names\n",
    "\n",
    "# Run models and compare results\n",
    "def run_models(df):\n",
    "    results = []\n",
    "    models = {}\n",
    "    \n",
    "    for feature_engineered in [False, True]:\n",
    "        X_train, X_test, y_train, y_test, feature_names = prepare_data(df, feature_engineered)\n",
    "        \n",
    "        for model_name in ['RandomForest', 'LinearRegression']:\n",
    "            result, model, _, feature_names = train_and_evaluate(X_train, X_test, y_train, y_test, model_name, feature_names)\n",
    "            result['Feature Engineered'] = feature_engineered\n",
    "            results.append(result)\n",
    "            models[(model_name, feature_engineered)] = (model, feature_names)\n",
    "    \n",
    "    return pd.DataFrame(results), models\n",
    "\n",
    "# Run the analysis\n",
    "results, models = run_models(df)\n",
    "print(results)\n",
    "\n",
    "# Function to demonstrate predictions as percentages\n",
    "def predict_diabetes_probability(model, feature_names, X, feature_engineered=True):\n",
    "    original_columns = X.columns.tolist()\n",
    "    \n",
    "    if feature_engineered:\n",
    "        X = feature_engineering(X)\n",
    "    \n",
    "    # Ensure all columns from the training data are present\n",
    "    for col in feature_names:\n",
    "        if col not in X.columns:\n",
    "            X[col] = 0  # Add missing columns with default value 0\n",
    "    \n",
    "    # Select only the columns used during training\n",
    "    X = X[feature_names]\n",
    "    \n",
    "    X = X.drop(['Diabetes_binary', 'Diabetes_percentage'], axis=1, errors='ignore')\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    probabilities = model.predict(X_scaled)\n",
    "    return probabilities, original_columns\n",
    "\n",
    "# Example usage\n",
    "sample_data = df.sample(5)  # Take 5 random samples from the dataset\n",
    "for (model_name, feature_eng), (model, feature_names) in models.items():\n",
    "    print(f\"\\nPredictions using {model_name} {'with' if feature_eng else 'without'} feature engineering:\")\n",
    "    probabilities, original_columns = predict_diabetes_probability(model, feature_names, sample_data, feature_eng)\n",
    "    for i, prob in enumerate(probabilities):\n",
    "        print(f\"Sample {i+1}: {prob:.2f}% chance of diabetes\")\n",
    "    \n",
    "    # Print feature importances for Random Forest\n",
    "    if model_name == 'RandomForest':\n",
    "        importances = model.feature_importances_\n",
    "        feature_imp = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "        feature_imp = feature_imp.sort_values('importance', ascending=False).head(10)\n",
    "        print(\"\\nTop 10 Feature Importances:\")\n",
    "        print(feature_imp)\n",
    "    \n",
    "    # Print coefficients for Linear Regression\n",
    "    if model_name == 'LinearRegression':\n",
    "        coefficients = model.coef_\n",
    "        coef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "        coef_df = coef_df.sort_values('coefficient', ascending=False).head(10)\n",
    "        print(\"\\nTop 10 Coefficients:\")\n",
    "        print(coef_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
