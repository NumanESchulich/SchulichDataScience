{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalink = \"https://raw.githubusercontent.com/delinai/schulich_ds1_2024/main/Datasets/Employee_Attrition_Data_Set.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Load & Null Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Null Count, Null Percentage]\n",
      "Index: []\n",
      "There are no null values in the dataset.\n",
      "                      Data Type    count       mean          std     min  \\\n",
      "Employee ID               int64  10000.0     5000.5   2886.89568     1.0   \n",
      "Age                       int64  10000.0    40.5612    10.876483    22.0   \n",
      "Gender                   object    10000        NaN          NaN     NaN   \n",
      "Job Role                 object    10000        NaN          NaN     NaN   \n",
      "Department               object    10000        NaN          NaN     NaN   \n",
      "Monthly Income            int64  10000.0  8948.7503  3473.354793  3000.0   \n",
      "Years at Company          int64  10000.0    14.3111     8.742572     0.0   \n",
      "Number of Promotions      int64  10000.0     1.9583     1.426171     0.0   \n",
      "Last Raise Percentage   float64  10000.0  10.022797     5.823696     0.0   \n",
      "Distance from Office    float64  10000.0  26.632481    14.396393     1.0   \n",
      "Job Satisfaction          int64  10000.0      5.407     2.943504     1.0   \n",
      "Performance Rating        int64  10000.0     2.9929     1.410833     1.0   \n",
      "Attrition                object    10000        NaN          NaN     NaN   \n",
      "\n",
      "                             25%       50%        75%      max  Null Count  \\\n",
      "Employee ID              2500.75    5000.5    7500.25  10000.0           0   \n",
      "Age                         31.0      41.0       50.0     59.0           0   \n",
      "Gender                       NaN       NaN        NaN      NaN           0   \n",
      "Job Role                     NaN       NaN        NaN      NaN           0   \n",
      "Department                   NaN       NaN        NaN      NaN           0   \n",
      "Monthly Income            5895.0    8982.5   11928.25  14999.0           0   \n",
      "Years at Company             7.0      14.0       22.0     30.0           0   \n",
      "Number of Promotions         1.0       2.0        3.0      5.0           0   \n",
      "Last Raise Percentage   5.101189  9.990978  15.042273     20.0           0   \n",
      "Distance from Office   14.509275  27.12293  39.148606     50.0           0   \n",
      "Job Satisfaction             3.0       5.0        8.0     10.0           0   \n",
      "Performance Rating           2.0       3.0        4.0      5.0           0   \n",
      "Attrition                    NaN       NaN        NaN      NaN           0   \n",
      "\n",
      "                       Null Percentage  \n",
      "Employee ID                        0.0  \n",
      "Age                                0.0  \n",
      "Gender                             0.0  \n",
      "Job Role                           0.0  \n",
      "Department                         0.0  \n",
      "Monthly Income                     0.0  \n",
      "Years at Company                   0.0  \n",
      "Number of Promotions               0.0  \n",
      "Last Raise Percentage              0.0  \n",
      "Distance from Office               0.0  \n",
      "Job Satisfaction                   0.0  \n",
      "Performance Rating                 0.0  \n",
      "Attrition                          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Read the data file\n",
    "df = pd.read_csv(datalink)\n",
    "\n",
    "# Check for null values\n",
    "null_counts = df.isnull().sum()\n",
    "null_percentages = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "# Combine the counts and percentages into a single dataframe\n",
    "null_table = pd.concat([null_counts, null_percentages], axis=1, keys=['Null Count', 'Null Percentage'])\n",
    "\n",
    "# Sort the table by null count in descending order\n",
    "null_table = null_table.sort_values('Null Count', ascending=False)\n",
    "\n",
    "# Display only columns with null values\n",
    "print(null_table[null_table['Null Count'] > 0])\n",
    "\n",
    "# If there are no null values, print a message\n",
    "if null_table['Null Count'].sum() == 0:\n",
    "    print(\"There are no null values in the dataset.\")\n",
    "\n",
    "# Quick summary of data\n",
    "def summarize_dataframe(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'Data Type': df.dtypes,\n",
    "        'Non-Null Count': df.notnull().sum(),\n",
    "        'Null Count': df.isnull().sum(),\n",
    "        'Unique Values': df.nunique(),\n",
    "        'First Value': df.iloc[0],\n",
    "        'Second Value': df.iloc[1],\n",
    "        'Third Value': df.iloc[2]\n",
    "    })\n",
    "    \n",
    "    summary['Null Percentage'] = (100 * summary['Null Count'] / len(df)).round(1)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Get the summary of the DataFrame\n",
    "summary_df = df.describe(include='all').transpose()\n",
    "\n",
    "# Add additional information\n",
    "summary_df['Null Count'] = df.isnull().sum()\n",
    "summary_df['Null Percentage'] = (100 * df.isnull().sum() / len(df)).round(1)\n",
    "summary_df['Data Type'] = df.dtypes\n",
    "\n",
    "# Reorder columns for readability\n",
    "summary_df = summary_df[['Data Type', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'Null Count', 'Null Percentage']]\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary Employee ID Column\n",
    "columns_to_drop = ['Employee ID'] \n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns for Ease of Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename specific columns\n",
    "df = df.rename(columns={'old_name1': 'new_name1', 'old_name2': 'new_name2'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing Nulls with Mean of Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to clean\n",
    "columns_to_clean = ['COLUMN_NAME1', 'COLUMN_NAME2', 'COLUMN_NAME3']  # Replace with the names of the columns you want to clean\n",
    "\n",
    "# Iterate through each column and replace null values with the mean\n",
    "for column in columns_to_clean:\n",
    "    mean_value = df[column].mean()\n",
    "    df[column].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winsorize some Column with Bad Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns you want to winsorize\n",
    "columns_to_winsorize = ['COLUMN_NAME1', 'COLUMN_NAME2', 'COLUMN_NAME3']  # Replace with the names of the columns you want to winsorize\n",
    "\n",
    "# Define the proportion of data to winsorize\n",
    "winsorize_limits = 0.05  # Replace with your desired limit (e.g., 0.05 for 5%)\n",
    "\n",
    "# Apply winsorization to each specified column\n",
    "for column in columns_to_winsorize:\n",
    "    df[column] = winsorize(df[column], limits=winsorize_limits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to clean\n",
    "columns_to_clean = ['COLUMN_NAME1', 'COLUMN_NAME2', 'COLUMN_NAME3']  # Replace 'COLUMN_NAME' with the name of the column you want to clean\n",
    "\n",
    "# Remove rows with null values in the specified columns and overwrite the original DataFrame\n",
    "df = df.dropna(subset=columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning & Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Function to format y-axis labels with \"K\" for thousands\n",
    "def format_yaxis(ax):\n",
    "    ylabels = ax.get_yticks()\n",
    "    ax.set_yticks(ylabels)\n",
    "    ax.set_yticklabels([f'{int(y/1000)}K' for y in ylabels])\n",
    "\n",
    "# Function to bin data\n",
    "def bin_data(data, bins, labels):\n",
    "    return pd.cut(data, bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Bin Column1, Column2, and Column3\n",
    "df['GenHelth_binned'] = bin_data(df['GenHlth'], \n",
    "                                 bins=[0, 1, 5, 10, 15, 30], \n",
    "                                 labels=['0', '1-5', '6-10', '11-15', '16+'])\n",
    "\n",
    "\n",
    "# 1. Distribution of the target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='Diabetes_binary', data=df)  # Replace 'TargetVariable' with your target column name\n",
    "format_yaxis(ax)\n",
    "plt.title('Distribution of Target Variable', fontweight='bold')\n",
    "plt.xlabel('Target Variable (Description)', fontweight='bold')  # Replace description with relevant information\n",
    "plt.ylabel('Count', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# 2. Distribution of numerical features\n",
    "numerical_features = ['BMI','PhysHlth','MentHlth']  # Replace with your numerical column names\n",
    "df[numerical_features].hist(bins=15, figsize=(15, 10), layout=(3, 3))\n",
    "plt.suptitle('Distribution of Numerical Features', fontweight='bold')\n",
    "for ax in plt.gcf().axes:\n",
    "    format_yaxis(ax)\n",
    "plt.show()\n",
    "\n",
    "# 3. Distribution of binary features\n",
    "binary_features = ['Smoker', 'Fruits', 'Stroke']  # Replace with your binary column names\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 16))\n",
    "for i, feature in enumerate(binary_features):\n",
    "    row, col = divmod(i, 3)\n",
    "    ax = sns.countplot(x=feature, data=df, ax=axes[row, col])\n",
    "    format_yaxis(ax)\n",
    "    axes[row, col].set_title(f'Distribution of {feature}', fontweight='bold')\n",
    "plt.suptitle('Distribution of Binary Features', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Correlation matrix\n",
    "# Select only numeric columns for correlation\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "corr_df = df[numeric_columns]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "corr = corr_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "# 5. Relationships between features and the target variable\n",
    "# Update numerical_features list with binned versions\n",
    "numerical_features = ['Column1_binned', 'Column2', 'Column2_binned', 'Column3_binned', 'Column4', 'Column5', 'Column6']  # Replace with your binned and other numerical columns\n",
    "binary_features = ['Column7', 'Column8']  # Replace with your binary columns\n",
    "\n",
    "# Calculate the number of rows and columns for the subplot grid\n",
    "n_numerical = len(numerical_features)\n",
    "n_binary = len(binary_features)\n",
    "n_cols = 4\n",
    "n_rows = -(-n_numerical // n_cols) + -(-n_binary // n_cols)  # Ceiling division\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "fig.suptitle('Relationships between Features and Target Variable', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot relationships for numerical features\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    sns.countplot(x=feature, hue='TargetVariable', data=df, ax=axes[row, col])  # Replace 'TargetVariable' with your target column name\n",
    "    axes[row, col].set_title(f'{feature}', fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Number of Individuals')\n",
    "    axes[row, col].legend(title='Target Variable', labels=['No', 'Yes'])  # Replace labels if needed\n",
    "    axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    format_yaxis(axes[row, col])  # Ensure you have the format_yaxis function defined\n",
    "\n",
    "# Plot relationships for binary features\n",
    "start_row = -(-n_numerical // n_cols)  # Ceiling division\n",
    "for i, feature in enumerate(binary_features):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    row += start_row\n",
    "    sns.countplot(x=feature, hue='TargetVariable', data=df, ax=axes[row, col])  # Replace 'TargetVariable' with your target column name\n",
    "    axes[row, col].set_title(f'{feature}', fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature)\n",
    "    axes[row, col].set_ylabel('Number of Individuals')\n",
    "    axes[row, col].legend(title='Target Variable', labels=['No', 'Yes'])  # Replace labels if needed\n",
    "    format_yaxis(axes[row, col])  # Ensure you have the format_yaxis function defined\n",
    "\n",
    "# Remove any unused subplots\n",
    "for i in range(n_numerical + n_binary, n_rows * n_cols):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Adjust to make room for the suptitle\n",
    "plt.show()\n",
    "\n",
    "# 6. Relationships between features and the target variable (Percentage Stacked Bar Charts)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(24, 5*n_rows))  # Increased figure width\n",
    "fig.suptitle('Relationships between Features and Target Variable (Percentage)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Function to create percentage stacked bar chart\n",
    "def percentage_stacked_bar(feature, ax):\n",
    "    # Calculate percentages\n",
    "    percentages = df.groupby(feature, observed=True)['TargetVariable'].value_counts(normalize=True).unstack()  # Replace 'TargetVariable' with your target column name\n",
    "    # Plot stacked bar chart\n",
    "    percentages.plot(kind='bar', stacked=True, ax=ax, width=0.8)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_title(f'{feature}', fontweight='bold')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Move legend outside the plot\n",
    "    ax.legend(title='Target Variable', labels=['No', 'Yes'], bbox_to_anchor=(1.05, 1), loc='upper left')  # Replace labels if needed\n",
    "\n",
    "# Plot relationships for numerical features\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    percentage_stacked_bar(feature, axes[row, col])\n",
    "\n",
    "# Plot relationships for binary features\n",
    "start_row = -(-n_numerical // n_cols)  # Ceiling division\n",
    "for i, feature in enumerate(binary_features):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    row += start_row\n",
    "    percentage_stacked_bar(feature, axes[row, col])\n",
    "\n",
    "# Remove any unused subplots\n",
    "for i in range(n_numerical + n_binary, n_rows * n_cols):\n",
    "    row, col = divmod(i, n_cols)\n",
    "    fig.delaxes(axes[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95, right=0.9)  # Adjust to make room for the suptitle and legends\n",
    "plt.show()\n",
    "\n",
    "# List of categorical columns to test\n",
    "categorical_columns = ['Column8', 'Column9', 'Column10', 'Column11', 'Column12', 'Column13', 'Column14', 'Column15', 'Column16', 'Column17', 'Column18', 'Column19', 'Column20', 'Column21', 'Column22']  # Replace with your categorical columns\n",
    "\n",
    "# Target variable\n",
    "target = 'TargetVariable'  # Replace with your target column name\n",
    "\n",
    "# Perform Chi-Square test\n",
    "chi2_results = {}\n",
    "for column in categorical_columns:\n",
    "    contingency_table = pd.crosstab(df[column], df[target])\n",
    "    chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "    chi2_results[column] = {'chi2': chi2, 'p-value': p}\n",
    "\n",
    "# Convert results to DataFrame\n",
    "chi2_results_df = pd.DataFrame.from_dict(chi2_results, orient='index').reset_index()\n",
    "chi2_results_df.columns = ['Feature', 'Chi2', 'p-value']\n",
    "\n",
    "# Sort results by Chi2 score in descending order, then by p-value\n",
    "chi2_results_df.sort_values(by=['Chi2', 'p-value'], ascending=[False, True], inplace=True)\n",
    "chi2_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi-Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify categorical columns\n",
    "def get_categorical_columns(df):\n",
    "    return df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Identify categorical columns in the DataFrame\n",
    "categorical_columns = get_categorical_columns(df)\n",
    "\n",
    "# Specify your target variable column name\n",
    "target_variable = 'TargetVariable'  # Replace with your actual target variable column name\n",
    "\n",
    "# Ensure the target variable is categorical\n",
    "if df[target_variable].dtype != 'object' and not pd.api.types.is_categorical_dtype(df[target_variable]):\n",
    "    df[target_variable] = df[target_variable].astype('category')\n",
    "\n",
    "# Perform Chi-Square test for each categorical column against the target variable\n",
    "chi2_results = {}\n",
    "for column in categorical_columns:\n",
    "    if column != target_variable:  # Skip the target variable itself\n",
    "        contingency_table = pd.crosstab(df[column], df[target_variable])\n",
    "        chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
    "        chi2_results[column] = {'chi2': chi2, 'p-value': p}\n",
    "\n",
    "# Convert results to DataFrame\n",
    "chi2_results_df = pd.DataFrame.from_dict(chi2_results, orient='index').reset_index()\n",
    "chi2_results_df.columns = ['Feature', 'Chi2', 'p-value']\n",
    "\n",
    "# Sort results by Chi2 score in descending order, then by p-value\n",
    "chi2_results_df.sort_values(by=['Chi2', 'p-value'], ascending=[False, True], inplace=True)\n",
    "chi2_results_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the results\n",
    "print(chi2_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Categorical to 0 and 1 (May not be Needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'Column1': [10, 5, 0, 8, 12]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert values > 0 to 1, and 0 or less to 0\n",
    "df['Column1_categorical'] = df['Column1'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'text_column': ['apple', 'banana', 'cherry', 'apple']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# List of values to match\n",
    "values_to_match = ['apple', 'cherry']\n",
    "\n",
    "# Convert text values to 1 if they match any value in the list, else 0\n",
    "df['binary_column'] = df['text_column'].apply(lambda x: 1 if x in values_to_match else 0)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineered Columns\n",
    "df['Column1'] = (df['Column1'] + df['Column1'] + df['Column1'] + df['Column1']) / 4\n",
    "df['Column1'] = (df['Column1'] + df['Column1'] + df['Column1'] + df['Column1']) / 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target variable\n",
    "feature_columns = ['feature1', 'feature2', 'feature3'] # Replace with your actual feature columns\n",
    "target_variable = 'Target Variable'\n",
    "\n",
    "# Split the data\n",
    "X = df[feature_columns]\n",
    "y = df[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    results.append([model_name, accuracy, precision, recall, f1])\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Print the results in a tabular format\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision_0', 'Recall_0', 'F1_0', 'Precision_1', 'Recall_1', 'F1_1'])\n",
    "\n",
    "# Print the results in a tabular format\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load your data\n",
    "# df = pd.read_csv('your_data.csv') # Uncomment and replace with your file path\n",
    "\n",
    "# Define feature columns and target variable\n",
    "feature_columns = ['feature1', 'feature2', 'feature3'] # Replace with your actual feature columns\n",
    "target_variable = 'Target Variable'\n",
    "\n",
    "# Split the data\n",
    "X = df[feature_columns]\n",
    "y = df[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "    precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "    recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "    recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "    f1_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "    f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    \n",
    "    results.append([model_name, accuracy, precision_0, recall_0, f1_0, precision_1, recall_1, f1_1])\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1], yticklabels=[0, 1])\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "    # Print the classification report\n",
    "    print(f'{model_name} Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision_0', 'Recall_0', 'F1_0', 'Precision_1', 'Recall_1', 'F1_1'])\n",
    "\n",
    "# Print the results in a tabular format\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "# results_df.to_csv('model_results.csv', index=False) # Uncomment to save results to a file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load your data\n",
    "# df = pd.read_csv('your_data.csv') # Uncomment and replace with your file path\n",
    "\n",
    "# Define feature columns and target variable\n",
    "feature_columns = ['feature1', 'feature2', 'feature3'] # Replace with your actual feature columns\n",
    "target_variable = 'Target Variable'\n",
    "\n",
    "# Split the data\n",
    "X = df[feature_columns]\n",
    "y = df[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class weights to give more weight to the minority class\n",
    "class_counts = y_train.value_counts()\n",
    "minority_class = class_counts.idxmin()\n",
    "majority_class = class_counts.idxmax()\n",
    "\n",
    "# Assign weights (e.g., give the minority class 2x the weight of the majority class)\n",
    "class_weight = {majority_class: 1, minority_class: 2}\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision for class 0: {precision_0:.4f}')\n",
    "print(f'Recall for class 0: {recall_0:.4f}')\n",
    "print(f'F1 Score for class 0: {f1_0:.4f}')\n",
    "print(f'Precision for class 1: {precision_1:.4f}')\n",
    "print(f'Recall for class 1: {recall_1:.4f}')\n",
    "print(f'F1 Score for class 1: {f1_1:.4f}')\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One with Threshold Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load your data\n",
    "# df = pd.read_csv('your_data.csv') # Uncomment and replace with your file path\n",
    "\n",
    "# Define feature columns and target variable\n",
    "feature_columns = ['feature1', 'feature2', 'feature3'] # Replace with your actual feature columns\n",
    "target_variable = 'Target Variable'\n",
    "\n",
    "# Split the data\n",
    "X = df[feature_columns]\n",
    "y = df[target_variable]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Set a custom threshold\n",
    "threshold = 0.3 # Adjust the threshold value as needed\n",
    "y_pred = (y_probs >= threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision_0 = precision_score(y_test, y_pred, pos_label=0)\n",
    "precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall_0 = recall_score(y_test, y_pred, pos_label=0)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1_0 = f1_score(y_test, y_pred, pos_label=0)\n",
    "f1_1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision for class 0: {precision_0:.4f}')\n",
    "print(f'Recall for class 0: {recall_0:.4f}')\n",
    "print(f'F1 Score for class 0: {f1_0:.4f}')\n",
    "print(f'Precision for class 1: {precision_1:.4f}')\n",
    "print(f'Recall for class 1: {recall_1:.4f}')\n",
    "print(f'F1 Score for class 1: {f1_1:.4f}')\n",
    "\n",
    "# Print the confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
