{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Read data file\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/NumanESchulich/SchulichDataScience/main/AI%20Fundamentals%20(MMAI%205000S)/AI-Human%20Pew%20Data.csv\")\n",
    "\n",
    "# Define the SMALG columns & Demographic Columns\n",
    "smalg_columns = ['SMALG2_W99', 'SMALG4_a_W99', 'SMALG4_b_W99', 'SMALG4_c_W99', \n",
    "                 'SMALG4_d_W99', 'SMALG7_W99', 'SMALG11_W99', 'SMALG12_W99']\n",
    "\n",
    "demographic_columns = ['F_INTFREQ', 'F_RELCOM3CAT', 'F_METRO', 'F_CREGION', 'F_CDIVISION', 'F_AGECAT',\n",
    "                     'F_GENDER', 'F_EDUCCAT2', 'F_HISP', \n",
    "                     'F_YEARSINUS', 'F_RACECMB', 'F_RACETHNMOD', 'F_CITIZEN',\n",
    "                     'F_MARITAL', 'F_RELIG', 'F_ATTEND', 'F_RELIMP',\n",
    "                     'F_PRAY', 'F_PARTY_FINAL', 'F_PARTYSUM_FINAL',\n",
    "                     'F_PARTYSUMIDEO_FINAL', 'F_INC_SDT1', 'F_IDEO', 'F_VOLSUM']\n",
    "\n",
    "# Select the specified columns\n",
    "selected_columns = smalg_columns + demographic_columns\n",
    "\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Rename the new columns to start with \"DEM_\"\n",
    "rename_dict = {col: f\"DEM_{col}\" for col in selected_columns if col.startswith('F_')}\n",
    "df_selected = df_selected.rename(columns=rename_dict)\n",
    "\n",
    "# Filter out null values from SMALG columns\n",
    "df_selected = df_selected.dropna(subset=smalg_columns)\n",
    "\n",
    "# Filter out \"Refused\" responses from SMALG columns\n",
    "for col in smalg_columns:\n",
    "    df_selected = df_selected[df_selected[col] != 'Refused']\n",
    "\n",
    "# Replace nulls and \"Refused\" with specified values for DEM columns\n",
    "df_selected['DEM_F_INTFREQ'] = df_selected['DEM_F_INTFREQ'].replace(['Refused', None, ''], 'Several times a day')\n",
    "df_selected['DEM_F_RELCOM3CAT'] = df_selected['DEM_F_RELCOM3CAT'].replace('DK/Ref', 'Medium')\n",
    "df_selected['DEM_F_AGECAT'] = df_selected['DEM_F_AGECAT'].replace('Refused', '30-49')\n",
    "df_selected['DEM_F_GENDER'] = df_selected['DEM_F_GENDER'].replace('Refused', 'In some other way')\n",
    "\n",
    "# Replace everything not \"Republican\" or \"Democrat\" with \"Other\" in DEM_F_PARTY_FINAL\n",
    "df_selected['DEM_F_PARTY_FINAL'] = df_selected['DEM_F_PARTY_FINAL'].apply(lambda x: x if x in ['Republican', 'Democrat'] else 'Other')\n",
    "\n",
    "# Mapping for specified columns\n",
    "mapping = {\n",
    "    'SMALG2_W99': {'Good idea for society': 1, 'Not sure': 0.5, 'Bad idea for society': 0},\n",
    "    'SMALG4_a_W99': {'Definitely happening': 0, 'Probably happening': 0.33, 'Probably NOT happening': 0.67, 'Definitely NOT happening': 1},\n",
    "    'SMALG4_b_W99': {'Definitely happening': 0, 'Probably happening': 0.33, 'Probably NOT happening': 0.67, 'Definitely NOT happening': 1},\n",
    "    'SMALG4_c_W99': {'Definitely happening': 1, 'Probably happening': 0.67, 'Probably NOT happening': 0.33, 'Definitely NOT happening': 0},\n",
    "    'SMALG4_d_W99': {'Definitely happening': 1, 'Probably happening': 0.67, 'Probably NOT happening': 0.33, 'Definitely NOT happening': 0},\n",
    "    'SMALG7_W99': {'A great deal of confidence': 1, 'A fair amount of confidence': 0.67, 'Not too much confidence': 0.33, 'No confidence at all': 0},\n",
    "    'SMALG11_W99': {'Mostly made by computer programs': 1, 'Not sure': 0.5, 'A mix of both people and computer programs': 0.5, 'Mostly made by people': 0},\n",
    "    'SMALG12_W99': {'A better job than humans': 1, 'About the same job as humans': 0.5, 'Not sure': 0.5, 'A worse job than humans': 0}\n",
    "}\n",
    "\n",
    "# Apply the mappings\n",
    "for col, map_dict in mapping.items():\n",
    "    df_selected[col] = df_selected[col].map(map_dict)\n",
    "\n",
    "# Calculate Trust Score\n",
    "weights = {\n",
    "    'SMALG2_W99': 0.2143,\n",
    "    'SMALG4_a_W99': 0.0476,\n",
    "    'SMALG4_b_W99': 0.0476,\n",
    "    'SMALG4_c_W99': 0.0476,\n",
    "    'SMALG4_d_W99': 0.0476,\n",
    "    'SMALG7_W99': 0.2391,\n",
    "    'SMALG11_W99': 0.1667,\n",
    "    'SMALG12_W99': 0.1905\n",
    "}\n",
    "\n",
    "df_selected['Trust Score'] = sum(df_selected[col] * weight for col, weight in weights.items())\n",
    "\n",
    "# Drop SMALG columns\n",
    "df_selected = df_selected.drop(columns=smalg_columns)\n",
    "\n",
    "# Apply changes to demographic columns\n",
    "dem_mappings = {\n",
    "    'DEM_F_INTFREQ': {'Almost constantly': 1, 'Several times a day': 0.75, 'About once a day': 0.5, 'Several times a week': 0.25, 'Less often': 0},\n",
    "    'DEM_F_RELCOM3CAT': {'Low': 0, 'Medium': 0.5, 'High': 1},\n",
    "    'DEM_F_METRO': {'Metropolitan': 1, 'Non-metropolitan': 0},\n",
    "    'DEM_F_AGECAT': {'18-29': 1, '30-49': 0.75, '50-64': 0.5, '65+': 0.25},\n",
    "    'DEM_F_EDUCCAT2': {\"Postgraduate\": 1, \"College graduate/some post grad\": 0.8, \"Associate's degree\": 0.6, \"Some college, no degree\": 0.5, \"High school graduate\": 0.4, \"Less than high school\": 0.2, \"Refused\": 0.1},\n",
    "    'DEM_F_YEARSINUS': {'Born in US (not including unincorporated territories)': 1, '21+ years': 0.9, '11-20 years': 0.8, '0-10 years': 0.5, 'DK/Ref': 0.4},\n",
    "    'DEM_F_MARITAL': {'Married': 1, 'Living with a partner': 0.8, 'Widowed': 0.6, 'Never been married': 0.5, 'Separated': 0.4, 'Divorced': 0.3, 'Refused': 0.2},\n",
    "    'DEM_F_RELIG': {'Protestant': 1, 'Roman Catholic': 1, 'Nothing in particular': 0, 'Agnostic': 0, 'Atheist': 0, 'Other': 1, 'Jewish': 1, 'Mormon (Church of Jesus Christ of Latter-day Saints or LDS)': 1, 'Buddhist': 1, 'Hindu': 1, 'Muslim': 1, 'Orthodox (such as Greek, Russian, or some other Orthodox church)': 1, 'Refused': 0},\n",
    "    'DEM_F_RELIMP': {'Very important': 1, 'Somewhat important': 0.5, 'Not at all important': 0, 'Not too important': 0.25, 'Refused': 0},\n",
    "    'DEM_F_INC_SDT1': {'Refused': 0.4, 'Less than $30,000': 0, '$30,000 to less than $40,000': 0.1, '$50,000 to less than $60,000': 0.2, '$40,000 to less than $50,000': 0.3, '$60,000 to less than $70,000': 0.4, '$70,000 to less than $80,000': 0.5, '$90,000 to less than $100,000': 0.6, '$80,000 to less than $90,000': 0.7, '$100,000 or more': 1},\n",
    "    'DEM_F_IDEO': {'Very conservative': 0, 'Conservative': 0.25, 'Moderate': 0.5, 'Liberal': 0.75, 'Very liberal': 1, 'Refused': 0.5},\n",
    "    'DEM_F_VOLSUM': {'No': 0, 'Yes': 1, 'Refused': 0}\n",
    "}\n",
    "\n",
    "for col, map_dict in dem_mappings.items():\n",
    "    df_selected[col] = df_selected[col].map(map_dict)\n",
    "\n",
    "# Define the final dataset as TrustScoreDataset\n",
    "TrustScoreDataset = df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------+------------+--------+\n",
      "|    | Model                       |   R2 Score |   RMSE |\n",
      "|----+-----------------------------+------------+--------|\n",
      "|  0 | Linear Regression           |     0.2899 | 0.1710 |\n",
      "|  1 | Decision Tree Regressor     |    -0.5139 | 0.2497 |\n",
      "|  2 | Random Forest Regressor     |     0.2678 | 0.1737 |\n",
      "|  3 | Gradient Boosting Regressor |     0.2946 | 0.1704 |\n",
      "|  4 | Support Vector Regressor    |     0.2375 | 0.1772 |\n",
      "+----+-----------------------------+------------+--------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Continue from your previous code\n",
    "\n",
    "# Define the final dataset as TrustScoreDataset\n",
    "TrustScoreDataset = df_selected\n",
    "\n",
    "# Assuming the target variable is named 'Trust Score' and all other columns are features\n",
    "X = TrustScoreDataset.drop('Trust Score', axis=1)\n",
    "y = TrustScoreDataset['Trust Score']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "    'Support Vector Regressor': SVR()\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Using np.sqrt for RMSE calculation\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results.append({'Model': name, 'R2 Score': r2, 'RMSE': rmse})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results using tabulate\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql', floatfmt='.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting the Problem to Classification instead of Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------+------------+-------------+----------+------------+\n",
      "|    | Model                        |   Accuracy |   Precision |   Recall |   F1 Score |\n",
      "|----+------------------------------+------------+-------------+----------+------------|\n",
      "|  0 | Logistic Regression          |     0.6992 |      0.5915 |   0.6110 |     0.6011 |\n",
      "|  1 | Decision Tree Classifier     |     0.5894 |      0.4526 |   0.5096 |     0.4794 |\n",
      "|  2 | Random Forest Classifier     |     0.6768 |      0.5737 |   0.5014 |     0.5351 |\n",
      "|  3 | Gradient Boosting Classifier |     0.6839 |      0.5707 |   0.5973 |     0.5837 |\n",
      "|  4 | Support Vector Classifier    |     0.6911 |      0.5728 |   0.6575 |     0.6122 |\n",
      "+----+------------------------------+------------+-------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Continue from your previous code\n",
    "\n",
    "# Define the final dataset as TrustScoreDataset\n",
    "TrustScoreDataset = df_selected\n",
    "\n",
    "# Create a binary target variable\n",
    "TrustScoreDataset['Trust Category'] = (TrustScoreDataset['Trust Score'] > 0.5).astype(int)\n",
    "\n",
    "# Assuming all columns except 'Trust Score' and 'Trust Category' are features\n",
    "X = TrustScoreDataset.drop(['Trust Score', 'Trust Category'], axis=1)\n",
    "y = TrustScoreDataset['Trust Category']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models (now using classifiers instead of regressors)\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(random_state=42),\n",
    "    'Support Vector Classifier': SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results using tabulate\n",
    "print(tabulate(results_df, headers='keys', tablefmt='psql', floatfmt='.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.6972\n",
      "Precision: Class 0: 0.8365, Class 1: 0.5661\n",
      "Recall: Class 0: 0.6446, Class 1: 0.7863\n",
      "F1 Score: Class 0: 0.7281, Class 1: 0.6583\n",
      "Confusion Matrix:\n",
      "[[399 220]\n",
      " [ 78 287]]\n",
      "Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.6900\n",
      "Precision: Class 0: 0.8153, Class 1: 0.5617\n",
      "Recall: Class 0: 0.6559, Class 1: 0.7479\n",
      "F1 Score: Class 0: 0.7269, Class 1: 0.6416\n",
      "Confusion Matrix:\n",
      "[[406 213]\n",
      " [ 92 273]]\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.6890\n",
      "Precision: Class 0: 0.8227, Class 1: 0.5591\n",
      "Recall: Class 0: 0.6446, Class 1: 0.7644\n",
      "F1 Score: Class 0: 0.7228, Class 1: 0.6458\n",
      "Confusion Matrix:\n",
      "[[399 220]\n",
      " [ 86 279]]\n",
      "Best Parameters: {'max_depth': 10, 'n_estimators': 100}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.6890\n",
      "Precision: Class 0: 0.8240, Class 1: 0.5589\n",
      "Recall: Class 0: 0.6430, Class 1: 0.7671\n",
      "F1 Score: Class 0: 0.7223, Class 1: 0.6467\n",
      "Confusion Matrix:\n",
      "[[398 221]\n",
      " [ 85 280]]\n",
      "Best Parameters: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: SVC\n",
      "Accuracy: 0.6921\n",
      "Precision: Class 0: 0.8333, Class 1: 0.5608\n",
      "Recall: Class 0: 0.6381, Class 1: 0.7836\n",
      "F1 Score: Class 0: 0.7228, Class 1: 0.6537\n",
      "Confusion Matrix:\n",
      "[[395 224]\n",
      " [ 79 286]]\n",
      "Best Parameters: {'C': 10, 'kernel': 'rbf'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create binary target variable\n",
    "TrustScoreDataset['Trust Category'] = (TrustScoreDataset['Trust Score'] > 0.5).astype(int)\n",
    "\n",
    "# Assuming all columns except 'Trust Score' and 'Trust Category' are features\n",
    "X = TrustScoreDataset.drop(['Trust Score', 'Trust Category'], axis=1)\n",
    "y = TrustScoreDataset['Trust Category']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=10)\n",
    "X = rfe.fit_transform(X, y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models with hyperparameter grids\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42, solver='liblinear'), \n",
    "                            {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}),\n",
    "    'Decision Tree': (DecisionTreeClassifier(random_state=42),\n",
    "                      {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), \n",
    "                      {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(random_state=42), \n",
    "                          {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}),\n",
    "    'SVC': (SVC(random_state=42), \n",
    "            {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']})\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', error_score=0)\n",
    "    grid_search.fit(X_train_scaled, y_train_resampled)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (0/1)': precision,\n",
    "        'Recall (0/1)': recall,\n",
    "        'F1 Score (0/1)': f1,\n",
    "        'Confusion Matrix': cm,\n",
    "        'Best Parameters': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"\\nModel: {result['Model']}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: Class 0: {result['Precision (0/1)'][0]:.4f}, Class 1: {result['Precision (0/1)'][1]:.4f}\")\n",
    "    print(f\"Recall: Class 0: {result['Recall (0/1)'][0]:.4f}, Class 1: {result['Recall (0/1)'][1]:.4f}\")\n",
    "    print(f\"F1 Score: Class 0: {result['F1 Score (0/1)'][0]:.4f}, Class 1: {result['F1 Score (0/1)'][1]:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(result['Confusion Matrix'])\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost + Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.6860\n",
      "Precision: Class 0: 0.8326, Class 1: 0.5541\n",
      "Recall: Class 0: 0.6268, Class 1: 0.7863\n",
      "F1 Score: Class 0: 0.7152, Class 1: 0.6501\n",
      "Best Parameters: {'penalty': 'l1', 'C': 0.01}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.6870\n",
      "Precision: Class 0: 0.8288, Class 1: 0.5558\n",
      "Recall: Class 0: 0.6333, Class 1: 0.7781\n",
      "F1 Score: Class 0: 0.7179, Class 1: 0.6484\n",
      "Best Parameters: {'n_estimators': 100, 'min_samples_split': 5, 'max_depth': 10}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.6921\n",
      "Precision: Class 0: 0.8251, Class 1: 0.5622\n",
      "Recall: Class 0: 0.6478, Class 1: 0.7671\n",
      "F1 Score: Class 0: 0.7258, Class 1: 0.6489\n",
      "Best Parameters: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Neural Network\n",
      "Accuracy: 0.6951\n",
      "Precision: Class 0: 0.8372, Class 1: 0.5636\n",
      "Recall: Class 0: 0.6397, Class 1: 0.7890\n",
      "F1 Score: Class 0: 0.7253, Class 1: 0.6575\n",
      "Best Parameters: {'hidden_layer_sizes': (50, 50), 'alpha': 0.001}\n",
      "--------------------------------------------------\n",
      "\n",
      "Model: Voting Classifier\n",
      "Accuracy: 0.6951\n",
      "Precision: Class 0: 0.8372, Class 1: 0.5636\n",
      "Recall: Class 0: 0.6397, Class 1: 0.7890\n",
      "F1 Score: Class 0: 0.7253, Class 1: 0.6575\n",
      "Best Parameters: N/A\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Set the number of CPU cores to use\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '4'  # Adjust this number based on your system\n",
    "\n",
    "# Feature Engineering\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42, solver='liblinear'), \n",
    "                            {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), \n",
    "                      {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}),\n",
    "    'Gradient Boosting': (GradientBoostingClassifier(random_state=42),\n",
    "                          {'n_estimators': [100, 200, 300], 'max_depth': [3, 4, 5, 6], 'learning_rate': [0.01, 0.1, 0.3]}),\n",
    "    'Neural Network': (MLPClassifier(random_state=42, max_iter=1000),\n",
    "                       {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'alpha': [0.0001, 0.001, 0.01]})\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, (model, param_grid) in models.items():\n",
    "    # Calculate the total parameter space\n",
    "    n_iter = min(10, np.prod([len(v) for v in param_grid.values()]))\n",
    "    \n",
    "    random_search = RandomizedSearchCV(model, param_grid, n_iter=n_iter, cv=5, scoring='f1', random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train_scaled, y_train_resampled)\n",
    "    \n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision (0/1)': precision,\n",
    "        'Recall (0/1)': recall,\n",
    "        'F1 Score (0/1)': f1,\n",
    "        'Best Parameters': random_search.best_params_\n",
    "    })\n",
    "\n",
    "# Create a Voting Classifier\n",
    "best_models = [random_search.best_estimator_ for _, (_, _) in models.items()]\n",
    "voting_clf = VotingClassifier(estimators=[(name, model) for name, model in zip(models.keys(), best_models)], voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "\n",
    "# Add Voting Classifier results\n",
    "results.append({\n",
    "    'Model': 'Voting Classifier',\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_voting),\n",
    "    'Precision (0/1)': precision_score(y_test, y_pred_voting, average=None),\n",
    "    'Recall (0/1)': recall_score(y_test, y_pred_voting, average=None),\n",
    "    'F1 Score (0/1)': f1_score(y_test, y_pred_voting, average=None),\n",
    "    'Best Parameters': 'N/A'\n",
    "})\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    print(f\"\\nModel: {result['Model']}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: Class 0: {result['Precision (0/1)'][0]:.4f}, Class 1: {result['Precision (0/1)'][1]:.4f}\")\n",
    "    print(f\"Recall: Class 0: {result['Recall (0/1)'][0]:.4f}, Class 1: {result['Recall (0/1)'][1]:.4f}\")\n",
    "    print(f\"F1 Score: Class 0: {result['F1 Score (0/1)'][0]:.4f}, Class 1: {result['F1 Score (0/1)'][1]:.4f}\")\n",
    "    print(f\"Best Parameters: {result['Best Parameters']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso & Ridge for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO selected features: ['DEM_F_INTFREQ', 'DEM_F_EDUCCAT2', 'DEM_F_YEARSINUS', 'DEM_F_MARITAL', 'DEM_F_INC_SDT1', 'DEM_F_IDEO', 'DEM_F_GENDER_In some other way', 'DEM_F_RACECMB_Or some other race', 'DEM_F_RACETHNMOD_Other', 'DEM_F_RACETHNMOD_Refused', 'DEM_F_CITIZEN_Refused', 'DEM_F_CITIZEN_Yes', 'DEM_F_PRAY_Seldom', 'DEM_F_PRAY_Several times a day', 'DEM_F_PARTY_FINAL_Other', 'DEM_F_PARTYSUM_FINAL_Dem/Lean Dem', 'DEM_F_PARTYSUM_FINAL_Rep/Lean Rep', 'DEM_F_PARTYSUMIDEO_FINAL_Moderate/Liberal Rep/Lean']\n",
      "\n",
      "LASSO Results:\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.6382\n",
      "Precision: Class 0: 0.7020, Class 1: 0.5135\n",
      "Recall: Class 0: 0.7383, Class 1: 0.4685\n",
      "F1 Score: Class 0: 0.7197, Class 1: 0.4900\n",
      "\n",
      "Model: Neural Network\n",
      "Accuracy: 0.6453\n",
      "Precision: Class 0: 0.7157, Class 1: 0.5223\n",
      "Recall: Class 0: 0.7237, Class 1: 0.5123\n",
      "F1 Score: Class 0: 0.7197, Class 1: 0.5173\n",
      "\n",
      "Ridge selected features: ['DEM_F_INTFREQ', 'DEM_F_YEARSINUS', 'DEM_F_HISP_Yes', 'DEM_F_RACECMB_Black or African-American', 'DEM_F_RACECMB_Mixed Race', 'DEM_F_RACECMB_Or some other race', 'DEM_F_RACECMB_White', 'DEM_F_RACETHNMOD_Black non-Hispanic', 'DEM_F_RACETHNMOD_Hispanic', 'DEM_F_RACETHNMOD_White non-Hispanic', 'DEM_F_ATTEND_Never', 'DEM_F_ATTEND_Seldom', 'DEM_F_PARTY_FINAL_Other', 'DEM_F_PARTYSUM_FINAL_Dem/Lean Dem', 'DEM_F_PARTYSUM_FINAL_Rep/Lean Rep', 'DEM_F_PARTYSUMIDEO_FINAL_Liberal Dem/Lean', 'DEM_F_PARTYSUMIDEO_FINAL_Moderate/Conservative Dem/Lean', 'DEM_F_PARTYSUMIDEO_FINAL_Moderate/Liberal Rep/Lean']\n",
      "\n",
      "Ridge Results:\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.6778\n",
      "Precision: Class 0: 0.7428, Class 1: 0.5663\n",
      "Recall: Class 0: 0.7464, Class 1: 0.5616\n",
      "F1 Score: Class 0: 0.7446, Class 1: 0.5640\n",
      "\n",
      "Model: Neural Network\n",
      "Accuracy: 0.6758\n",
      "Precision: Class 0: 0.7358, Class 1: 0.5661\n",
      "Recall: Class 0: 0.7561, Class 1: 0.5397\n",
      "F1 Score: Class 0: 0.7458, Class 1: 0.5526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Assume TrustScoreDataset is already defined\n",
    "\n",
    "# Create binary target variable\n",
    "TrustScoreDataset['Trust Category'] = (TrustScoreDataset['Trust Score'] > 0.5).astype(int)\n",
    "\n",
    "# Prepare the data\n",
    "X = TrustScoreDataset.drop(['Trust Score', 'Trust Category'], axis=1)\n",
    "y = TrustScoreDataset['Trust Category']\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Function to perform feature selection and modeling\n",
    "def feature_selection_and_modeling(selector, X_train, X_test, y_train, y_test):\n",
    "    # Fit the selector\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Get selected feature mask\n",
    "    feature_mask = selector.get_support()\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[feature_mask].tolist()\n",
    "    \n",
    "    # Transform the data\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'Neural Network': MLPClassifier(random_state=42, max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=None)\n",
    "        recall = recall_score(y_test, y_pred, average=None)\n",
    "        f1 = f1_score(y_test, y_pred, average=None)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision (0/1)': precision,\n",
    "            'Recall (0/1)': recall,\n",
    "            'F1 Score (0/1)': f1\n",
    "        })\n",
    "    \n",
    "    return selected_features, results\n",
    "\n",
    "# LASSO feature selection\n",
    "lasso = Lasso(alpha=0.01, random_state=42)\n",
    "lasso_selector = SelectFromModel(lasso, prefit=False)\n",
    "lasso_features, lasso_results = feature_selection_and_modeling(lasso_selector, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "print(\"LASSO selected features:\", lasso_features)\n",
    "print(\"\\nLASSO Results:\")\n",
    "for result in lasso_results:\n",
    "    print(f\"\\nModel: {result['Model']}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: Class 0: {result['Precision (0/1)'][0]:.4f}, Class 1: {result['Precision (0/1)'][1]:.4f}\")\n",
    "    print(f\"Recall: Class 0: {result['Recall (0/1)'][0]:.4f}, Class 1: {result['Recall (0/1)'][1]:.4f}\")\n",
    "    print(f\"F1 Score: Class 0: {result['F1 Score (0/1)'][0]:.4f}, Class 1: {result['F1 Score (0/1)'][1]:.4f}\")\n",
    "\n",
    "# Ridge feature selection\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge_selector = SelectFromModel(ridge, prefit=False)\n",
    "ridge_features, ridge_results = feature_selection_and_modeling(ridge_selector, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n",
    "print(\"\\nRidge selected features:\", ridge_features)\n",
    "print(\"\\nRidge Results:\")\n",
    "for result in ridge_results:\n",
    "    print(f\"\\nModel: {result['Model']}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: Class 0: {result['Precision (0/1)'][0]:.4f}, Class 1: {result['Precision (0/1)'][1]:.4f}\")\n",
    "    print(f\"Recall: Class 0: {result['Recall (0/1)'][0]:.4f}, Class 1: {result['Recall (0/1)'][1]:.4f}\")\n",
    "    print(f\"F1 Score: Class 0: {result['F1 Score (0/1)'][0]:.4f}, Class 1: {result['F1 Score (0/1)'][1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
